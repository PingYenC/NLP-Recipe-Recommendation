{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8mhwQFfJuM2"
      },
      "outputs": [],
      "source": [
        "# importing inportant libraries\n",
        "import os\n",
        "import math\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.utils\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from flask import Flask, render_template, request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrSYmq0gKijy"
      },
      "source": [
        "**讀取資料 Load File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "DVULN2Uk2HZ3",
        "outputId": "8621ef3e-b718-4bfe-865d-83e87c8faa55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    title  \\\n",
              "0                       Slow Cooker Chicken and Dumplings   \n",
              "1                           Awesome Slow Cooker Pot Roast   \n",
              "2                                    Brown Sugar Meatloaf   \n",
              "3                             Best Chocolate Chip Cookies   \n",
              "4                       Homemade Mac and Cheese Casserole   \n",
              "...                                                   ...   \n",
              "114205                                 Apple Chimichangas   \n",
              "114206  Coconut-Kaffir Leaf Poached Halibut with Saute...   \n",
              "114207           Chicken Braised with 20 Cloves of Garlic   \n",
              "114208                                        Cream Horns   \n",
              "114209             Chocolate Cake with Armagnac Ice Cream   \n",
              "\n",
              "                                              ingredients  \\\n",
              "0       ['4 skinless, boneless chicken breast halves A...   \n",
              "1       ['2 (10.75 ounce) cans condensed cream of mush...   \n",
              "2       ['1/2 cup packed brown sugar ADVERTISEMENT', '...   \n",
              "3       ['1 cup butter, softened ADVERTISEMENT', '1 cu...   \n",
              "4       ['8 ounces whole wheat rotini pasta ADVERTISEM...   \n",
              "...                                                   ...   \n",
              "114205  ['1/4 cup butter', '1/3 cup sugar', '1 teaspoo...   \n",
              "114206  ['2 cups coconut milk', '1 short stalk lemon g...   \n",
              "114207  ['2 large heads garlic', '1 cut-up chicken, ab...   \n",
              "114208  ['1 sheet frozen puff pastry, thawed', '1 egg'...   \n",
              "114209  ['8 ounces butter', '8 ounces bittersweet choc...   \n",
              "\n",
              "                                             instructions  \n",
              "0       Place the chicken, butter, soup, and onion in ...  \n",
              "1       In a slow cooker, mix cream of mushroom soup, ...  \n",
              "2       Preheat oven to 350 degrees F (175 degrees C)....  \n",
              "3       Preheat oven to 350 degrees F (175 degrees C)....  \n",
              "4       Preheat oven to 350 degrees F. Line a 2-quart ...  \n",
              "...                                                   ...  \n",
              "114205  Watch how to make this recipe.\\nHeat a heavy m...  \n",
              "114206  Preheat the oven to 250 degrees F\\nIn a small ...  \n",
              "114207  Bring a small saucepan of water to a boil. Sep...  \n",
              "114208  Grease 8 cream horn metal cones. Cut the puff ...  \n",
              "114209  Preheat oven to 350 degrees. On the top half o...  \n",
              "\n",
              "[114210 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25a98d4e-ae1f-42bb-82d8-01fdf717815d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>instructions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Slow Cooker Chicken and Dumplings</td>\n",
              "      <td>['4 skinless, boneless chicken breast halves A...</td>\n",
              "      <td>Place the chicken, butter, soup, and onion in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Awesome Slow Cooker Pot Roast</td>\n",
              "      <td>['2 (10.75 ounce) cans condensed cream of mush...</td>\n",
              "      <td>In a slow cooker, mix cream of mushroom soup, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brown Sugar Meatloaf</td>\n",
              "      <td>['1/2 cup packed brown sugar ADVERTISEMENT', '...</td>\n",
              "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Best Chocolate Chip Cookies</td>\n",
              "      <td>['1 cup butter, softened ADVERTISEMENT', '1 cu...</td>\n",
              "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Homemade Mac and Cheese Casserole</td>\n",
              "      <td>['8 ounces whole wheat rotini pasta ADVERTISEM...</td>\n",
              "      <td>Preheat oven to 350 degrees F. Line a 2-quart ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114205</th>\n",
              "      <td>Apple Chimichangas</td>\n",
              "      <td>['1/4 cup butter', '1/3 cup sugar', '1 teaspoo...</td>\n",
              "      <td>Watch how to make this recipe.\\nHeat a heavy m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114206</th>\n",
              "      <td>Coconut-Kaffir Leaf Poached Halibut with Saute...</td>\n",
              "      <td>['2 cups coconut milk', '1 short stalk lemon g...</td>\n",
              "      <td>Preheat the oven to 250 degrees F\\nIn a small ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114207</th>\n",
              "      <td>Chicken Braised with 20 Cloves of Garlic</td>\n",
              "      <td>['2 large heads garlic', '1 cut-up chicken, ab...</td>\n",
              "      <td>Bring a small saucepan of water to a boil. Sep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114208</th>\n",
              "      <td>Cream Horns</td>\n",
              "      <td>['1 sheet frozen puff pastry, thawed', '1 egg'...</td>\n",
              "      <td>Grease 8 cream horn metal cones. Cut the puff ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114209</th>\n",
              "      <td>Chocolate Cake with Armagnac Ice Cream</td>\n",
              "      <td>['8 ounces butter', '8 ounces bittersweet choc...</td>\n",
              "      <td>Preheat oven to 350 degrees. On the top half o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114210 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25a98d4e-ae1f-42bb-82d8-01fdf717815d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25a98d4e-ae1f-42bb-82d8-01fdf717815d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25a98d4e-ae1f-42bb-82d8-01fdf717815d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4aae07d5-23e5-42c2-b325-0aa87849fc6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4aae07d5-23e5-42c2-b325-0aa87849fc6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4aae07d5-23e5-42c2-b325-0aa87849fc6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv(r'/content/drive/MyDrive/all_recipe.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZAmuffIKqQm",
        "outputId": "13aaf24c-a87c-4241-def7-fa2cc3ef6fc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Slow Cooker Chicken and Dumplings ['4 skinless...\n",
              "1         Awesome Slow Cooker Pot Roast ['2 (10.75 ounce...\n",
              "2         Brown Sugar Meatloaf ['1/2 cup packed brown su...\n",
              "3         Best Chocolate Chip Cookies ['1 cup butter, so...\n",
              "4         Homemade Mac and Cheese Casserole ['8 ounces w...\n",
              "                                ...                        \n",
              "114205    Apple Chimichangas ['1/4 cup butter', '1/3 cup...\n",
              "114206    Coconut-Kaffir Leaf Poached Halibut with Saute...\n",
              "114207    Chicken Braised with 20 Cloves of Garlic ['2 l...\n",
              "114208    Cream Horns ['1 sheet frozen puff pastry, thaw...\n",
              "114209    Chocolate Cake with Armagnac Ice Cream ['8 oun...\n",
              "Length: 114210, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 去除雜字 \"ADVERTISEMENT\"\n",
        "# Remove dummy words \"ADVERTISEMENT\"\n",
        "recipe = data['title'].astype(str) + ' ' + data['ingredients'].astype(str) + ' ' + data['instructions'].astype(str)\n",
        "recipe = [re.sub(r'\\b\\w*ADVERTISEMENT\\w*\\b', '', sentence) for sentence in recipe]\n",
        "recipe = [''.join(words) for words in recipe]\n",
        "recipe = pd.Series(recipe)\n",
        "recipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbX-UbgfKspX"
      },
      "source": [
        "# 試試TF-IDF!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "ywF_s5pTK2dm",
        "outputId": "8f2cae9b-615e-42cf-ad97-de52aaa3d2ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.9, min_df=0.05, ngram_range=(1, 3),\n",
              "                stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.9, min_df=0.05, ngram_range=(1, 3),\n",
              "                stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "TfidfVectorizer(max_df=0.9, min_df=0.05, ngram_range=(1, 3),\n",
              "                stop_words='english')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 用TF-IDF把食譜轉換成代碼，並存至字詞資料庫\n",
        "# Convert recipes into code using TF-IDF and save them to the word database\n",
        "tfidf = TfidfVectorizer(lowercase=True, stop_words='english', min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "tfidf.fit(recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjb0iGXR-hPa"
      },
      "outputs": [],
      "source": [
        "# 對食譜進行 TF-IDF 轉換\n",
        "# Perform TF-IDF transformation on recipes.\n",
        "recipe_data = tfidf.fit_transform(recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfdmkqh9K32J",
        "outputId": "e52d9046-e3fe-4eb1-9177-efe21017188c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is in your mind? \n",
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)?\n",
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)?\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is 0.5009983990147417:\n",
            "*Title:\n",
            "Soothing Hot Ginger Tea  \n",
            "\n",
            "*Ingredients:\n",
            "'1 (12 fl oz) can ginger ale (such as Canada Dry®) ', '1 black tea bag (such as Lipton®) ', '' \n",
            "\n",
            "*Instructions:\n",
            " Pour ginger ale into a microwave-safe mug. Heat in the microwave for 1 to 2 minutes.\n",
            "Steep tea bag in the hot ginger ale for 3 to 5 minutes.\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is 0.49697131070897377:\n",
            "*Title:\n",
            "Hot Apple-Ginger Toddy  \n",
            "\n",
            "*Ingredients:\n",
            "'6 oz. ginger-infused apple cider', 'Thin slice of fresh ginger or one piece of crystallized, candied ginger', '1 tsp. honey', \"2 oz. bourbon (Maker's Mark or Jim Beam are preferred)\", 'Slice of lemon' \n",
            "\n",
            "*Instructions:\n",
            " First - Ginger-infuse the cider: Peel and chop the ginger. Bring apple cider to a boil in a nonaluminum pot. Add several slices of cut and peeled ginger when cider boils. Turn heat off and steep for 30 minutes. Puree this mixture in a blender and strain through cheesecloth. Refrigerate until ready to use.\n",
            "Second - Make the ginger toddy: Heat the ginger-infused cider, but do not boil. Add bourbon. Stir in honey. Pour into a coffee mug. Garnish with lemon and ginger slice (or use crystallized ginger). \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is 0.47894883005834754:\n",
            "*Title:\n",
            "Chocolate Ginger Dipping Sauce  \n",
            "\n",
            "*Ingredients:\n",
            "'1 cup water', '2 tablespoons ginger juice*', '1 1/2 cup fine quality semi-sweet chocolate, chopped', \"2 teaspoons ground ginger, if you can't make ginger juice, omit and bump up the ground ginger to 1 heaping tablespoon\", 'Serving suggestion: fresh berries, fresh fruit chunks, marshmallows' \n",
            "\n",
            "*Instructions:\n",
            " Put the water and ginger juice into a medium saucepan and bring to a boil over medium high heat. Add the chopped chocolate and ground ginger and whisk until the sauce is smooth. Pour into a decorative bowl and serve immediately. The sauce will stay liquid for up to 2 hours. Serve with fresh berries, fresh fruit chunks and marshmallows. \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 隨機提取問題資料庫中的問題，並將其放入列表中\n",
        "# Allow user to input query\n",
        "question = input(\"What is in your mind? \\n\")\n",
        "\n",
        "# 對問題進行 TF-IDF 轉換\n",
        "# Perform TF-IDF transformation on user's query.\n",
        "X = tfidf.transform([question])\n",
        "\n",
        "# 計算餘弦相似度\n",
        "# Calculate cosine similarity\n",
        "cos_X = cosine_similarity(X, recipe_data)\n",
        "\n",
        "# 將相似度矩陣降序排序並取前三個最大值的索引\n",
        "# Get the top 3 results (recipes) that have high cosine similarity\n",
        "top_indices = np.argsort(cos_X[0])[-3:][::-1]\n",
        "\n",
        "print(question)\n",
        "print('---------------------------------------------------------------------------')\n",
        "\n",
        "# 打印相似度最高的三筆資料\n",
        "# Print the results\n",
        "for i, index in enumerate(top_indices, 1):\n",
        "    recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "    print(f\"Recommendation {i} , The similarity is {cos_X[0][index]}:\")\n",
        "    print('*Title:')\n",
        "    print(recipe_info[0],'\\n')\n",
        "    print('*Ingredients:')\n",
        "    print(recipe_info[1],'\\n')\n",
        "    print('*Instructions:')\n",
        "    print(recipe_info[2],'\\n')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DofIVI3yK5in"
      },
      "source": [
        "在TF-IDF上加SVD降維 / TFIDF + SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL6NzRpaK_5l",
        "outputId": "8a3d27cc-1c1f-4a3e-d540-1a911a533d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)?\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is 0.9460398688897547:\n",
            "*Title:\n",
            "Cocktail Wieners I  \n",
            "\n",
            "*Ingredients:\n",
            "'1 (16 ounce) can cranberry sauce ', '12 fluid ounces chili sauce ', '3 pounds beef cocktail wieners ', '' \n",
            "\n",
            "*Instructions:\n",
            " In a 4-quart saucepan over medium heat, combine cranberry sauce and chili sauce. Break the cranberry sauce into smaller pieces with wooden spoon to speed up the melting process. Stir and heat until the cranberry sauce is melted. Add the cocktail wieners and cook until the wieners are heated. Use toothpicks for serving.\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is 0.9429141505896389:\n",
            "*Title:\n",
            "Memphis Style Dry Ribs: Corky's Ribs  \n",
            "\n",
            "*Ingredients:\n",
            "'One 2- to 2 3/4-pound slab raw St. Louis cut pork spare ribs', '1 1/2 cups water (3 parts)', \"1/2 cup favorite BBQ sauce (1 part), plus more for basting (recommended: Corky's)\", \"Favorite dry rib seasoning (recommended: Corky's)\" \n",
            "\n",
            "*Instructions:\n",
            " Preheat a grill to medium heat with all of the coals on 1 side.\n",
            "Grill over indirect heat (meat side down) for approximately 2 hours, turning once, until internal temperature reaches 185 degrees F.\n",
            "Baste ribs on both sides during cooking with 3 parts water to 1 part BBQ sauce. Once the ribs reach 185 degrees F, baste again with full strength BBQ sauce and sprinkle liberally with dry rib seasoning. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is 0.9375574208702664:\n",
            "*Title:\n",
            "Soy Butter Sauce  \n",
            "\n",
            "*Ingredients:\n",
            "'1 tablespoon oyster sauce', '1 tablespoon soy sauce', '1 pound butter' \n",
            "\n",
            "*Instructions:\n",
            " Heat the oyster sauce and soy sauce and bring to a boil, then whisk in butter. \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 用 SVD 把資料降維度至10\n",
        "# Use SVD to reduce dimension to 10\n",
        "svd = TruncatedSVD(10)\n",
        "R = svd.fit_transform(recipe_data) # 用TF-IDF轉換過的recipe 降維 / Apply SVD on TFIDF-transformed recipe\n",
        "Q = svd.transform(X) # 用TF-IDF轉換過的qestion data 降維 / Apply SVD on TFIDF-transformed user's query\n",
        "\n",
        "# 計算餘弦相似度\n",
        "# Calculate Cosine Similarity\n",
        "cos_X = cosine_similarity(Q, R)\n",
        "\n",
        "# 將相似度矩陣降序排序並取前三個最大值的索引\n",
        "# Get the top 3 results (recipes) that have high cosine similarity\n",
        "top_indices = np.argsort(cos_X[0])[-3:][::-1]\n",
        "\n",
        "print(question)\n",
        "print('---------------------------------------------------------------------------')\n",
        "\n",
        "# 打印相似度最高的三筆資料\n",
        "# Print the results\n",
        "for i, index in enumerate(top_indices, 1):\n",
        "    recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "    print(f\"Recommendation {i} , The similarity is {cos_X[0][index]}:\")\n",
        "    print('*Title:')\n",
        "    print(recipe_info[0],'\\n')\n",
        "    print('*Ingredients:')\n",
        "    print(recipe_info[1],'\\n')\n",
        "    print('*Instructions:')\n",
        "    print(recipe_info[2],'\\n')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8E891LfLCd6"
      },
      "source": [
        "##### TF-IDF + SVD降維 的結果比較差! 所以TF-IDF的模型決定不用SVD / TFIDF + SVD shows a worse result! Thus, don't appply SVD on TFIDF here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPiaNOPSLH6j"
      },
      "source": [
        "# 試試word2vec! / Try Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_r4I_zWLMvs",
        "outputId": "7a3ccf5a-4db6-4f2b-8cd7-d9d82544af89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('idaho', 0.7747125029563904),\n",
              " ('russet', 0.7643802165985107),\n",
              " ('fingerling', 0.7537190914154053),\n",
              " ('waxy', 0.7322282195091248),\n",
              " ('lovin', 0.7312313318252563),\n",
              " ('brien', 0.7310512065887451),\n",
              " ('shoestring', 0.7225973606109619),\n",
              " ('hasselback', 0.7218263745307922),\n",
              " ('scalloped', 0.7189490795135498),\n",
              " ('flanagan', 0.7174539566040039)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "toks = []\n",
        "for s in recipe:\n",
        "  toks.append(simple_preprocess(s))\n",
        "\n",
        "# vector_size: 這個參數指定了每個單詞向量的維度。在這個例子中，每個單詞將被表示為一個200維的向量\n",
        "# window: 這個參數指定了在訓練過程中考慮的上下文窗口的大小。具體地說，它表示了在訓練過程中，每個單詞的上下文窗口可以包含的單詞數量\n",
        "# min_count: 這個參數指定了訓練過程中考慮的最小詞頻。具體地說，如果一個單詞在文本數據中出現的次數少於 min_count，那麼它將被忽略不計。\n",
        "# workers=4 表示使用 4 個線程來訓練模型，這樣可以利用多核處理器提高訓練效率\n",
        "model = Word2Vec(toks, vector_size=400, window=5, min_count=0, workers=4)\n",
        "\n",
        "# 提取詞向量：獲得訓練好的詞向量模型後，從模型中提取詞向量。這裡將 model.wv 中的詞向量提取出來，並保存在 word_vectors 中。\n",
        "word_vectors = model.wv\n",
        "\n",
        "# 看看sweet 被分類到甚麼同意字\n",
        "# See what words are considered to be in the same vector with the word \"sweet\"\n",
        "word_vectors.most_similar_cosmul(['sweet'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iaBoHoYLOiR"
      },
      "source": [
        "## Note:\n",
        "* 在計算TF-IDF（Term Frequency-Inverse Document Frequency）的餘弦相似度時，不需要考慮向量的大小:\n",
        "是因為TF-IDF的值是以每個文檔中每個詞的相對重要性為基礎計算的。當計算TF-IDF向量時，向量的大小（即向量的長度）已經被標準化，因此餘弦相似度計算僅僅考慮向量之間的角度。\n",
        "\n",
        "* 而在Word2Vec中，每個詞的詞向量表示其在向量空間中的位置，而這些向量的大小（即向量的長度）通常也是重要的。\n",
        "由於Word2Vec中的詞向量通常沒有被標準化，因此其大小（即向量的長度）可能會影響餘弦相似度的計算。為了確保比較的公平性，通常在計算Word2Vec向量的餘弦相似度時，會對詞向量進行正規化，以使它們具有單位長度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2-qScF1LP4g",
        "outputId": "5094faab-67c8-4808-822e-9e98fb117de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['have', 'tofu', 'and', 'soy', 'sauce', 'and', 'ginger', 'can', 'you', 'recommend', 'savory', 'dish', 'that', 'can', 'be', 'cooked', 'in', 'medium', 'minutes']\n",
            "question_vec_length: 19\n"
          ]
        }
      ],
      "source": [
        "# question = input(\"What is in your mind?\")\n",
        "# 將question轉成單詞列表\n",
        "# Convert the question into a list of words.\n",
        "question_tokens = simple_preprocess(question)\n",
        "print(question_tokens)\n",
        "\n",
        "# 獲得question的向量表示\n",
        "# Obtain the vector representation of the question\n",
        "question_vec = word_vectors[question_tokens]\n",
        "print('question_vec_length:',len(question_vec))\n",
        "\n",
        "# 計算question_vec的平均詞向量，以利之後比較cosine similarity\n",
        "# Calculate the average word vector of the question_vec for better comparison of cosine similarity later.\n",
        "question_avg_vec = np.mean([word_vectors[token] for token in question_tokens if token in word_vectors], axis=0)\n",
        "# 檢查是否有 NaN 值，如果有的話，則將其替換為 0\n",
        "# Replace those null values\n",
        "question_avg_vec = np.nan_to_num(question_avg_vec)\n",
        "# 正規化向量（可選）\n",
        "# Normalize the vector (optional).\n",
        "question_avg_vec /= np.linalg.norm(question_avg_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qeZp-mgLRO6",
        "outputId": "d348d59c-bd30-4319-de77-87012d477d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)?\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is 0.5385329127311707:\n",
            "*Title:\n",
            "African Ground Nut Stew  \n",
            "\n",
            "*Ingredients:\n",
            "'1 onion, diced', '2 to 3 pounds boneless chicken cut into chunks (I prefer thigh meat)', '1/2 jar natural peanut butter (no sugar or stabilizers added)', '1 can coconut milk (often in Asian grocery section)', '2 quart chicken stock, canned or homemade', '1 large bunch collard or other greens, chopped fairly finely and after removing center ribs (frozen, drained greens can be used as a substitute)', 'Sambal oelek, to taste (hot chili paste from Asian grocery section)', 'Cooked rice, as an accompaniment' \n",
            "\n",
            "*Instructions:\n",
            " Saute onions until translucent in a large saucepan. Add chicken pieces and saute until golden but not necessarily cooked through. Add coconut milk and stock and bring to a simmer. Once the liquid is simmering, add the peanut butter a spoonful at a time and keep stirring until it is well incorporated. The sauce should be fairly thick (stew like, not soup like), so you may need to add more peanut butter or loosen with water depending upon the ingredients you use. Add chopped collards/greens and cook until very wilted. Season, to taste, with chili paste/sambal oelek and salt.\n",
            "Serve over rice or other starch.\n",
            "Traditional African stiff porridge would be served on the side and used to dip into the sauce with one's hands. Pull off a piece the size of a meatball, use your thumb to make an impression in the porridge and use the divet to scoop up the stew and pop it into your mouth! Enjoy. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is 0.5309586524963379:\n",
            "*Title:\n",
            "Edamame with XO Sauce  \n",
            "\n",
            "*Ingredients:\n",
            "'1-ounce dry scallops, soaked in water overnight', '3/4-ounce dry shrimp, soaked in water overnight', \"6 ounces canola oil, for frying, see Cook's Note*\", '1-ounce shallots, chopped in food processor', '3/4 tablespoon garlic, chopped in food processor', '3/4 tablespoon finely chopped serrano chiles', '3 1/4 ounces prosciutto, finely diced', '3/4 tablespoon lemongrass, finely minced', '1 teaspoon sesame oil', '1 chile de arbol, finely minced in food processor', '1/2 tablespoon sugar', '1 teaspoon chicken bouillon', '1/2 teaspoon finely ground black pepper', '2 pounds plus 12 ounces frozen edamame', '4 ounces XO sauce', '1 tablespoon oyster sauce', '1 tablespoon sugar', '1 teaspoon togarashi' \n",
            "\n",
            "*Instructions:\n",
            " For the XO Sauce:\n",
            "Drain scallops and shrimp, process both seperately in food processor to shred and chop. Or they can be chopped by hand. Beginning with scallops, place in oil and cook until lightly browned, strain. Continue with this procedure with; shrimp, shallots, garlic, serrano chiles. When it comes time to cook the prosciutto, this will take a bit longer as you will want to render this until almost crisp as with bacon. Add remaining ingredients and mix well.\n",
            "This is best if used the following day so all the flavors may come together. This recipe can be made in large quantities and used at later dates. Can be stored in the refrigerator for up to 1 month. Can also be frozen.\n",
            "*Cook's Note: In a large sauce pot over medium heat add canola oil. Each ingredient will be fried or rendered in this pot. Each time an ingredient is cooked, it should be completely strained from the oil and the oil returned to the pot for the next batch. Careful not to burn anything as you will want to use the oil in the final product to add flavor. If anything is burned then this will impart a bitter flavor. After each ingredient is cooked they can mixed into a common container.\n",
            "For the Edamame:\n",
            "In a pot of boiling water, blanch the edamame, strain. In a wok/saute pan with a small amount of cooking oil, saute cooked edamame with remaining ingredients and toss vigorously. Serve immediately. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is 0.5219170451164246:\n",
            "*Title:\n",
            "Curtis Aikens' Abc Soup  \n",
            "\n",
            "*Ingredients:\n",
            "'1/4 to 1/2 pound asparagus, cut into 1 inch pieces', '6 artichoke bottoms (hearts) cut into quarters', '2 heads of broccoli (and their trimmed stalks) cut into pieces', '3 carrots, peeled and cut into pieces', '1 medium daikon, peeled and cut into pieces', '1 tablespoon minced lemongrass or 1/2 teaspoon yellow lemon peel, grated', 'Kernels of 3 ears of corn', '1/4 teaspoon nutmeg', '1 white onion, peeled and diced', '1 yellow onion, peeled and diced', '1 bunch of green onions, diced' \n",
            "\n",
            "*Instructions:\n",
            " E is for Eggplant, not usually found in soups, but eggplant works, especially if you can find the small green Thai eggplant. You don't even have to peel them, just remove their caps. If you don't find Thai eggplant, purple eggplant will do nicely! 12 small Thai eggplant or 1 purple eggplant, peeled, diced and slightly sauteed in olive oil F is for Fungi; that means mushrooms! Any mushrooms will work; White button or Shiitake or Oyster. 2 handfuls of mushrooms, chopped and sauteed with a little bit of olive oil G is for Ginger. A fabulous root spice, the best of which comes from our 50th state, Hawaii. 1/4 to 1/2 teaspoon Ginger root, peeled and very finely chopped. H is for HOT. If you like your soups spicy hot, you can add Habanero peppers, which is the hottest pepper of all. Not everyone appreciates Habanero; in this soup they are optional and should be handled by grown ups only! 2 to 3 Habaneros, seeded and finely diced I is for Ingredients. This is what cooks call all of the things that go into a recipe. I have never found a vegetable that starts with the letter I. If you can think of one, please let me know!! J is for Jicama, a delicious root vegetable, which is quite popular in the tropical regions of the world, and looks very much like a potato. 1/4 cup jicama, peeled and diced K is for Kohlrabi, a great vegetable that comes in red, green and sometimes white. The leafy top and globe shaped bottom are all good to eat. A few diced kohlrabi leaves or 1/8 cup kohlrabi bottom, peeled and diced ;\n",
            "A is for vitamin A. We all know that Vitamin A is found in carrots, but it's also found in green vegetables like Asparagus and Artichokes .\n",
            "B is for Broccoli. Former President Bush was famous for not enjoying broccoli, but his wife Barbara loved it, and she was dedicated to the cause of reading, all across this country. I hope you'll join me in thanking Barbara Bush for all of her work with literacy. .\n",
            "C is for Carrots, yummy! I love carrots; they're sweet, crunchy and good for the eyes, teeth and bones. .\n",
            "D is for Daikon, a vegetable used a lot in Asian cuisine. It adds a wonderful flavor to soup.\n",
            "P is for Pepper, the black kind. I was once asked if I could pick only 2 spices, which ones would they be. My answer? Salt and Pepper! Pepper to taste (in a pot of soup like this one, 1 teaspoon is a good place to start) Q is for questions. My question: Have we forgotten anything, like maybe a delicious green vegetable that belongs in our soup? I say Yes! Let's revisit \"C\" and add some Celery! 1 small bunch of celery, diced Q is also for Quarter. We need a Quarter cup of liquid; you can add water or vegetable juice for broth, which should be combined with 1 teaspoon of butter for a smooth texture. R is for Rosemary, a herb which goes wonderfully in soup. 2 teaspoons fresh Rosemary S is for Salt, Sage and Savory Spices--all things that wake up the natural flavor of our vegetable soup. 1 teaspoon each of Sage and savory Herb de Provence Salt to taste T is for Tomato, one of my very favorite things to put into soup 4 red Tomatoes, diced T is also for Thyme, another great herb. 1/4 teaspoon Thyme Which sounds like \"Time\", something our soup also needs. After our alphabet has been completed, bring the soup to a quick boil, reduce heat, and simmer for 45 to 60 minutes. U is for \"You\"; make sure that you add something that You enjoy. My soup is always made from vegetables, but You may want to add fish or chicken or ground meat. Saute or grill it first, with a little bit of salt and pepper;\n",
            "L is for Lemongrass, which is used a lot in Asia. If you can't find it, you can substitute a little lemon juice, or a little of its peel. .\n",
            "M is for Maize, the Native American word for corn .\n",
            "N is for Nutmeg, a wonderful spice that smells good too! .\n",
            "O is for Onion. My favorites are the big white ones, the sweet yellow ones, and the Spring green ones .\n",
            "X is for no vegetable that I've ever heard of. If you can think of one, I hope you'll let me know. In the meantime, did you know that some people write the letter \"X\" as the symbol for a kiss? So when you have a steaming bowl of hot soup in front of you, you might want to blow a kiss into it; it's a lovely way to cool it off. Y is for Yams. Here in America, Yams are a variety of sweet potato. 2 medium Yams, peeled and diced Y is also for Yukon Gold, a yellow-fleshed potato which will help to make our soup nice and thick. 3 large Yukon Gold potatoes, peeled and diced Z is for Zucchini, one of my favorites! 3 medium Zucchini, sliced into wheels Method: Bring to a boil and simmer for 45 to 60 minutes. Your broth will be slowly created in the process. Check your seasoning during the cooking process, and add spices to taste. You may want to add 3 to 4 tablespoons of olive oil to thicken the broth and to add richness.;\n",
            "V is for Vegetable; the Vegetable of your choice that isn't in the pot yet (maybe cabbage, squash, bell pepper, Brussels sprouts, cauliflower, garlic cloves, anything you can think of!) .\n",
            "V is also for Victory. While I stir this soup, I thank God for my Victory over illiteracy. Not only can I read wonderful recipes, I can write them too, for you to read and to enjoy preparing! .\n",
            "W is for Water, which won't be necessary if you cover the pot while the soup is simmering (this may be a good moment for you parents to explain to your kids how liquid evaporates, or rises in the form of steam). .\n",
            "If your pot is uncovered, add 1/4 cup water .\n",
            "If you plan to use a lid, you can chop some Watercress or Water Chestnuts, to make sure that there is a \"W\" in the soup. \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 對於question資料庫中的每一個問題，找到最相近的三個食譜\n",
        "print(question)\n",
        "print('---------------------------------------------------------------------------')\n",
        "\n",
        "# recipe = data['title'].astype(str) + ' ' + data['ingredients'].astype(str) + ' ' + data['instructions'].astype(str)\n",
        "\n",
        "recipe_similarity = []\n",
        "for content in recipe:\n",
        "    content_tokens = simple_preprocess(content)\n",
        "    #content_vec = word_vectors[content_tokens]\n",
        "    # 計算平均詞向量\n",
        "    recipe_avg_vec = np.mean([word_vectors[token] for token in content_tokens if token in word_vectors], axis=0)\n",
        "    # 檢查是否有 NaN 值，如果有的話，則將其替換為 0\n",
        "    recipe_avg_vec = np.nan_to_num(recipe_avg_vec)\n",
        "    # 正規化向量（可選）\n",
        "    recipe_avg_vec /= np.linalg.norm(recipe_avg_vec)\n",
        "    recipe_similarity.append(np.dot(question_avg_vec, recipe_avg_vec))\n",
        "\n",
        "# 抓相似度前三的食譜index以及similarity\n",
        "# Get the top 3 results (recipes) that have high similarity\n",
        "top3_indices = np.argsort(recipe_similarity)[::-1][:3]\n",
        "\n",
        "for i, index in enumerate(top3_indices, 1):\n",
        "    recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "    print(f\"Recommendation {i} , The similarity is {recipe_similarity[index]}:\")\n",
        "    print('*Title:')\n",
        "    print(recipe_info[0],'\\n')\n",
        "    print('*Ingredients:')\n",
        "    print(recipe_info[1],'\\n')\n",
        "    print('*Instructions:')\n",
        "    print(recipe_info[2],'\\n')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgAPbpO2LSzS",
        "outputId": "9565a933-f751-4fc1-d748-0fadcc5c3eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)?\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is 0.8685928583145142:\n",
            "*Title:\n",
            "African Ground Nut Stew  \n",
            "\n",
            "*Ingredients:\n",
            "'1 onion, diced', '2 to 3 pounds boneless chicken cut into chunks (I prefer thigh meat)', '1/2 jar natural peanut butter (no sugar or stabilizers added)', '1 can coconut milk (often in Asian grocery section)', '2 quart chicken stock, canned or homemade', '1 large bunch collard or other greens, chopped fairly finely and after removing center ribs (frozen, drained greens can be used as a substitute)', 'Sambal oelek, to taste (hot chili paste from Asian grocery section)', 'Cooked rice, as an accompaniment' \n",
            "\n",
            "*Instructions:\n",
            " Saute onions until translucent in a large saucepan. Add chicken pieces and saute until golden but not necessarily cooked through. Add coconut milk and stock and bring to a simmer. Once the liquid is simmering, add the peanut butter a spoonful at a time and keep stirring until it is well incorporated. The sauce should be fairly thick (stew like, not soup like), so you may need to add more peanut butter or loosen with water depending upon the ingredients you use. Add chopped collards/greens and cook until very wilted. Season, to taste, with chili paste/sambal oelek and salt.\n",
            "Serve over rice or other starch.\n",
            "Traditional African stiff porridge would be served on the side and used to dip into the sauce with one's hands. Pull off a piece the size of a meatball, use your thumb to make an impression in the porridge and use the divet to scoop up the stew and pop it into your mouth! Enjoy. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is 0.8631609082221985:\n",
            "*Title:\n",
            "Chowders   \n",
            "\n",
            "*Ingredients:\n",
            "'4 ounces (2/3 cup) diced blanched salt pork or bacon', '1 Tbs butter', '3 cups (1 pound) sliced onions', '1 imported bay leaf', '3/4 cup crumbled \"common\" or pilot crackers, or 1 pressed-down cup fresh white bread crumbs', '6 cups liquid (milk, chicken stock, fish stock, clam juices, or a combination)', '3 1/2 cups (1 pound) peeled and sliced or diced boiling potatoes', 'Salt and freshly ground white pepper' \n",
            "\n",
            "*Instructions:\n",
            " Sauté the pork or bacon bits slowly with the butter in a large saucepan for 5 minutes, or until pieces begin to brown. Stir in the onions and bay leaf; cover, and cook slowly 8 to 10 minutes, until the onions are tender. Drain off fat and blend crackers or bread crumbs into onions. Pour in the liquid; add the potatoes and simmer, loosely covered, for 20 minutes or so, until the potatoes are tender. Season to taste with salt and white pepper, and the soup base is ready.\n",
            "Sauté the pork or bacon bits slowly with the butter in a large saucepan for 5 minutes, or until pieces begin to brown. Stir in the onions and bay leaf; cover, and cook slowly 8 to 10 minutes, until the onions are tender. Drain off fat and blend crackers or bread crumbs into onions. Pour in the liquid; add the potatoes and simmer, loosely covered, for 20 minutes or so, until the potatoes are tender. Season to taste with salt and white pepper, and the soup base is ready.\n",
            "Chowder Suggestions:\n",
            "New England clam chowder: For about 2 1/2 quarts, serving 6 to 8. Scrub and soak 24 medium-size hard-shell clams. Steam them for 3 to 4 minutes in a large tightly covered saucepan with 1 cup water, until most have opened. Remove the opened clams; cover, and steam the rest another minute or so. Discard any unopened clams. Pluck meat from the shells, then decant steaming-liquid very carefully, so all sand remains in the saucepan; include the clam-steaming liquid as part of the chowder base. Meanwhile, mince the clam meats in a food processor or chop by hand. Fold them into the finished chowder base. Just before serving, heat to below the simmer--so the clams won't overcook and toughen. Fold in a little heavy cream or sour cream if you wish; thin with milk if necessary, correct seasoning, and serve. To prepare clams: Scrub one at a time under running water, discarding any that are cracked, damaged, or not tightly closed. Soak 30 minutes in a basin of salted water (1/3 cup salt per 4 quarts water). Lift out, and if more than a few grains of sand remain in the basin, repeat. Refrigerate, covered by a damp towel. It's wise to use them within a day or two.\n",
            "For about 2 1/2 quarts, serving 6 to 8. Scrub and soak 24 medium-size hard-shell clams. Steam them for 3 to 4 minutes in a large tightly covered saucepan with 1 cup water, until most have opened. Remove the opened clams; cover, and steam the rest another minute or so. Discard any unopened clams. Pluck meat from the shells, then decant steaming-liquid very carefully, so all sand remains in the saucepan; include the clam-steaming liquid as part of the chowder base. Meanwhile, mince the clam meats in a food processor or chop by hand. Fold them into the finished chowder base. Just before serving, heat to below the simmer--so the clams won't overcook and toughen. Fold in a little heavy cream or sour cream if you wish; thin with milk if necessary, correct seasoning, and serve.\n",
            "To prepare clams: Scrub one at a time under running water, discarding any that are cracked, damaged, or not tightly closed. Soak 30 minutes in a basin of salted water (1/3 cup salt per 4 quarts water). Lift out, and if more than a few grains of sand remain in the basin, repeat. Refrigerate, covered by a damp towel. It's wise to use them within a day or two.\n",
            "Fish chowder: Prepare the chowder base using fish stock, and/or light chicken stock, and milk. Cut into 2-inch chunks 2 to 2 1/2 pounds of skinless, boneless lean fish, such as cod, haddock, halibut, monkfish, or sea bass, all one kind or a mixture. Add to the finished chowder base and simmer 2 to 3 minutes, just until fish is opaque and springy. Correct seasoning, and top each serving, if you wish, with a spoonful of sour cream.\n",
            "Prepare the chowder base using fish stock, and/or light chicken stock, and milk. Cut into 2-inch chunks 2 to 2 1/2 pounds of skinless, boneless lean fish, such as cod, haddock, halibut, monkfish, or sea bass, all one kind or a mixture. Add to the finished chowder base and simmer 2 to 3 minutes, just until fish is opaque and springy. Correct seasoning, and top each serving, if you wish, with a spoonful of sour cream.\n",
            "Chicken chowder: Prepare the chowder base using 6 cups of light chicken stock and milk. Stir 3 cups or so of grated fresh corn into the finished base, adding, if you wish, 2 green and/or red peppers chopped fine and sautéed briefly in butter. Bring to the simmer for 2 to 3 minutes; correct seasoning, and top each serving, if you wish, with a spoonful of sour cream.\n",
            "Prepare the chowder base using 6 cups of light chicken stock and milk. Stir 3 cups or so of grated fresh corn into the finished base, adding, if you wish, 2 green and/or red peppers chopped fine and sautéed briefly in butter. Bring to the simmer for 2 to 3 minutes; correct seasoning, and top each serving, if you wish, with a spoonful of sour cream.\n",
            "Corn chowder: Prepare the chowder base using 6 cups of light chicken stock and milk. Stir 3 cups or so of grated fresh corn into the finished base, adding, if you wish, 2 green and/or red peppers chopped fine and sautéed briefly in butter. Bring to the simmer for 2 to 3 minutes; correct seasoning, and top each serving, if you wish, with a spoonful of sour cream.\n",
            "Prepare the chowder base using 6 cups of light chicken stock and milk. Stir 3 cups or so of grated fresh corn into the finished base, adding, if you wish, 2 green and/or red peppers chopped fine and sautéed briefly in butter. Bring to the simmer for 2 to 3 minutes; correct seasoning, and top each serving, if you wish, with a spoonful of sour cream. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is 0.8558197617530823:\n",
            "*Title:\n",
            "Edamame with XO Sauce  \n",
            "\n",
            "*Ingredients:\n",
            "'1-ounce dry scallops, soaked in water overnight', '3/4-ounce dry shrimp, soaked in water overnight', \"6 ounces canola oil, for frying, see Cook's Note*\", '1-ounce shallots, chopped in food processor', '3/4 tablespoon garlic, chopped in food processor', '3/4 tablespoon finely chopped serrano chiles', '3 1/4 ounces prosciutto, finely diced', '3/4 tablespoon lemongrass, finely minced', '1 teaspoon sesame oil', '1 chile de arbol, finely minced in food processor', '1/2 tablespoon sugar', '1 teaspoon chicken bouillon', '1/2 teaspoon finely ground black pepper', '2 pounds plus 12 ounces frozen edamame', '4 ounces XO sauce', '1 tablespoon oyster sauce', '1 tablespoon sugar', '1 teaspoon togarashi' \n",
            "\n",
            "*Instructions:\n",
            " For the XO Sauce:\n",
            "Drain scallops and shrimp, process both seperately in food processor to shred and chop. Or they can be chopped by hand. Beginning with scallops, place in oil and cook until lightly browned, strain. Continue with this procedure with; shrimp, shallots, garlic, serrano chiles. When it comes time to cook the prosciutto, this will take a bit longer as you will want to render this until almost crisp as with bacon. Add remaining ingredients and mix well.\n",
            "This is best if used the following day so all the flavors may come together. This recipe can be made in large quantities and used at later dates. Can be stored in the refrigerator for up to 1 month. Can also be frozen.\n",
            "*Cook's Note: In a large sauce pot over medium heat add canola oil. Each ingredient will be fried or rendered in this pot. Each time an ingredient is cooked, it should be completely strained from the oil and the oil returned to the pot for the next batch. Careful not to burn anything as you will want to use the oil in the final product to add flavor. If anything is burned then this will impart a bitter flavor. After each ingredient is cooked they can mixed into a common container.\n",
            "For the Edamame:\n",
            "In a pot of boiling water, blanch the edamame, strain. In a wok/saute pan with a small amount of cooking oil, saute cooked edamame with remaining ingredients and toss vigorously. Serve immediately. \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 進行 SVD 降維至10\n",
        "# Apply SVD on Word2Vec\n",
        "svd = TruncatedSVD(10)\n",
        "svd.fit(word_vectors.vectors)\n",
        "word_vectors_svd = svd.transform(word_vectors.vectors)\n",
        "\n",
        "# 計算 question_vec 的平均詞向量，以利之後比較 cosine similarity\n",
        "# Calculate the similarity score\n",
        "question_avg_vec = np.mean([word_vectors_svd[word_vectors.index_to_key.index(token)] for token in question_tokens if token in word_vectors], axis=0)\n",
        "# 檢查是否有 NaN 值，如果有的話，則將其替換為 0\n",
        "question_avg_vec = np.nan_to_num(question_avg_vec)\n",
        "# 正規化向量（可選）\n",
        "question_avg_vec /= np.linalg.norm(question_avg_vec)\n",
        "\n",
        "# 對於 question 資料庫中的每一個問題，找到最相近的三個食譜\n",
        "print(question)\n",
        "print('---------------------------------------------------------------------------')\n",
        "\n",
        "recipe_similarity = []\n",
        "for content in recipe:\n",
        "    content_tokens = simple_preprocess(content)\n",
        "    # 計算平均詞向量\n",
        "    recipe_avg_vec = np.mean([word_vectors_svd[word_vectors.index_to_key.index(token)] for token in content_tokens if token in word_vectors], axis=0)\n",
        "    # 檢查是否有 NaN 值，如果有的話，則將其替換為 0\n",
        "    recipe_avg_vec = np.nan_to_num(recipe_avg_vec)\n",
        "    # 正規化向量（可選）\n",
        "    recipe_avg_vec /= np.linalg.norm(recipe_avg_vec)\n",
        "    recipe_similarity.append(np.dot(question_avg_vec, recipe_avg_vec))\n",
        "\n",
        "# 抓相似度前三的食譜index以及similarity\n",
        "# Get the top 3 results (recipes) that have high similarity\n",
        "top3_indices = np.argsort(recipe_similarity)[::-1][:3]\n",
        "\n",
        "for i, index in enumerate(top3_indices, 1):\n",
        "    recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "    print(f\"Recommendation {i} , The similarity is {recipe_similarity[index]}:\")\n",
        "    print('*Title:')\n",
        "    print(recipe_info[0],'\\n')\n",
        "    print('*Ingredients:')\n",
        "    print(recipe_info[1],'\\n')\n",
        "    print('*Instructions:')\n",
        "    print(recipe_info[2],'\\n')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgDNVtl4LXZM"
      },
      "source": [
        "##### word2vec的推薦結果肉眼可見的比TF-IDF差，但word2vec + SVD降維 的結果更差! 所以決定不用word2vec + SVD推薦了 / The result of Word2Vec seems terrible, and don't even mention Word2Vec + SVD! Thus, don't use Word2Vec apprach here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i1qtDKOMBTY"
      },
      "source": [
        "#試試 Count Vectorizer / Try Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSIAvNZ8MIQJ",
        "outputId": "d2190293-dafa-4156-be7e-1498ed09ac2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)?\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is [[0.2962963]]:\n",
            "*Title:\n",
            "Soy Butter Sauce  \n",
            "\n",
            "*Ingredients:\n",
            "'1 tablespoon oyster sauce', '1 tablespoon soy sauce', '1 pound butter' \n",
            "\n",
            "*Instructions:\n",
            " Heat the oyster sauce and soy sauce and bring to a boil, then whisk in butter. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is [[0.23577236]]:\n",
            "*Title:\n",
            "Grilled Pork Chops with Bourbon-Mustard Glaze   \n",
            "\n",
            "*Ingredients:\n",
            "'1/3 cup bottled chili sauce', '1/4 cup bourbon', '1 1/2 tablespoons Dijon mustard', '1 1/2 tablespoons reduced-sodium soy sauce', '4 thin-cut pork rib chops (each about 1/4 to 1/3 inch thick)' \n",
            "\n",
            "*Instructions:\n",
            " Prepare barbecue (medium-high heat). Combine chili sauce, bourbon, mustard and soy sauce in heavy medium saucepan. Simmer over medium heat until sauce is reduced enough to coat spoon, whisking occasionally, about 4 minutes. Sprinkle both sides of chops with salt and pepper. Brush 1 side of chops generously with sauce. Place chops, sauce side down, on grill. Brush chops generously with remaining sauce. Grill until cooked through and glazed, about 3 minutes per side.\n",
            "Prepare barbecue (medium-high heat). Combine chili sauce, bourbon, mustard and soy sauce in heavy medium saucepan. Simmer over medium heat until sauce is reduced enough to coat spoon, whisking occasionally, about 4 minutes.\n",
            "Sprinkle both sides of chops with salt and pepper. Brush 1 side of chops generously with sauce. Place chops, sauce side down, on grill. Brush chops generously with remaining sauce. Grill until cooked through and glazed, about 3 minutes per side. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is [[0.23214286]]:\n",
            "*Title:\n",
            "Nessie's Barbeque Sauce  \n",
            "\n",
            "*Ingredients:\n",
            "'1 cup tomato sauce ', '1 cup brown sauce ', '3 teaspoons hot chile sauce ', '3 teaspoons Worcestershire sauce ', '3 teaspoons dark soy sauce ', '6 fluid ounces cola-flavored carbonated beverage ', '' \n",
            "\n",
            "*Instructions:\n",
            " In a large bowl, combine tomato sauce, brown sauce, chili sauce, Worcestershire sauce, soy sauce and cola beverage. Place meat into marinade and turn to coat both sides. Cover and refrigerate overnight.\n",
            " \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# 轉vectorize\n",
        "# Transform to vectorize\n",
        "vectorizer = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words='english')\n",
        "recipe_bow = vectorizer.fit_transform(recipe)\n",
        "question_bow = vectorizer.transform([question])\n",
        "\n",
        "# 算 Jaccard Similarity\n",
        "# Calculte Jaccard Similarity\n",
        "recipe_intersections = recipe_bow.multiply(question_bow).sum(axis=1)\n",
        "recipe_unions = recipe_bow.sum(axis=1) + question_bow.sum(axis=1) - recipe_intersections\n",
        "jaccard_similarity = recipe_intersections / recipe_unions\n",
        "\n",
        "# 抓前三相似\n",
        "# Get the top 3 results (recipes) that have high similarity\n",
        "top_indices = jaccard_similarity.argsort(axis=0)[-3:][::-1]\n",
        "top_indices = np.ravel(top_indices)\n",
        "\n",
        "print(question)\n",
        "print('---------------------------------------------------------------------------')\n",
        "\n",
        "for i, index in enumerate(top_indices, 1):\n",
        "    recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "    print(f\"Recommendation {i} , The similarity is {jaccard_similarity[index][0]}:\")\n",
        "    print('*Title:')\n",
        "    print(recipe_info[0],'\\n')\n",
        "    print('*Ingredients:')\n",
        "    print(recipe_info[1],'\\n')\n",
        "    print('*Instructions:')\n",
        "    print(recipe_info[2],'\\n')\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI3yvf1pbhNF"
      },
      "source": [
        "# 結合 TF-IDF 和 CountVectorizer，輸出更好的推薦: / Combine TF-IDF and CountVectorizer to a mixed approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyFr9LgAUTlL",
        "outputId": "39ee16cb-cf98-43a8-e8f0-b1ed055534b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.05226535, 0.        , 0.066961  , ..., 0.1122359 , 0.0077773 ,\n",
              "       0.01781115])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cos_X = np.ravel(cos_X)\n",
        "cos_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiEU-1uFUTd4",
        "outputId": "1ee87ca7-3acc-4164-d51c-dc5796273f92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.02702703, 0.        , 0.00952381, ..., 0.05687204, 0.00684932,\n",
              "       0.015625  ])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jaccard_similarity = np.ravel(jaccard_similarity)\n",
        "jaccard_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPSu7Tz4Uoag",
        "outputId": "931b9247-e8d7-4a4f-fef7-41dc74260eab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.07929238, 0.        , 0.07648481, ..., 0.16910794, 0.01462662,\n",
              "       0.03343615])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarity = cos_X + jaccard_similarity\n",
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avguF5jFUMTR",
        "outputId": "2b7dc62e-b0c6-485e-cf54-900ba70cf43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 20566 106391  19739]\n",
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)?\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is 0.649810640831991:\n",
            "*Title:\n",
            "Sesame Ginger Sauce  \n",
            "\n",
            "*Ingredients:\n",
            "'2 tablespoons soy sauce ', '1 tablespoon Dijon mustard ', '1/4 teaspoon sesame oil ', '1/4 teaspoon grated fresh ginger root ', '2 1/2 teaspoons water ', '' \n",
            "\n",
            "*Instructions:\n",
            " In a small bowl, whisk together soy sauce, mustard, sesame oil, ginger root, and water.\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is 0.6499124871795621:\n",
            "*Title:\n",
            "Hot Apple-Ginger Toddy  \n",
            "\n",
            "*Ingredients:\n",
            "'6 oz. ginger-infused apple cider', 'Thin slice of fresh ginger or one piece of crystallized, candied ginger', '1 tsp. honey', \"2 oz. bourbon (Maker's Mark or Jim Beam are preferred)\", 'Slice of lemon' \n",
            "\n",
            "*Instructions:\n",
            " First - Ginger-infuse the cider: Peel and chop the ginger. Bring apple cider to a boil in a nonaluminum pot. Add several slices of cut and peeled ginger when cider boils. Turn heat off and steep for 30 minutes. Puree this mixture in a blender and strain through cheesecloth. Refrigerate until ready to use.\n",
            "Second - Make the ginger toddy: Heat the ginger-infused cider, but do not boil. Add bourbon. Stir in honey. Pour into a coffee mug. Garnish with lemon and ginger slice (or use crystallized ginger). \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is 0.6563392723493751:\n",
            "*Title:\n",
            "Tangy Ginger Dip  \n",
            "\n",
            "*Ingredients:\n",
            "'1 cup mayonnaise ', '4 teaspoons soy sauce ', '1 teaspoon white vinegar ', '1 teaspoon ground ginger ', '2 tablespoons minced onion ', '1 dash habanero garlic hot pepper sauce ', '' \n",
            "\n",
            "*Instructions:\n",
            " In a small bowl, stir together the mayonnaise, soy sauce, vinegar, ginger, onion, and hot sauce. Chill until serving.\n",
            " \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 抓前三相似\n",
        "# Get the top 3 results (recipes) that have high similarity\n",
        "top_indices = similarity.argsort(axis=0)[-3:]\n",
        "\n",
        "print(top_indices)\n",
        "print(question)\n",
        "print('---------------------------------------------------------------------------')\n",
        "\n",
        "for i, index in enumerate(top_indices, 1):\n",
        "    recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "    print(f\"Recommendation {i} , The similarity is {similarity[index]}:\")\n",
        "    print('*Title:')\n",
        "    print(recipe_info[0],'\\n')\n",
        "    print('*Ingredients:')\n",
        "    print(recipe_info[1],'\\n')\n",
        "    print('*Instructions:')\n",
        "    print(recipe_info[2],'\\n')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aAHa6y0b5-t"
      },
      "source": [
        "# 試試先把料理分類再比對tf-idf的cosine similarity，並產出最後的model / Try categorizing dishes first, then compare the cosine similarity of TF-IDF, and generate the final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNAJmoPicH5I"
      },
      "outputs": [],
      "source": [
        "# 把recipe 逐詞拆開以利比對\n",
        "# Categorize the recipe based on key words\n",
        "recipe1 = recipe.apply(lambda x: x.split())\n",
        "\n",
        "indian_cuisine = ['Indian']\n",
        "mexican_cuisine = ['Mexican']\n",
        "french_cuisine = ['French']\n",
        "italian_cuisine = ['Italian']\n",
        "japanese_cuisine = ['Japanese']\n",
        "korean_cuisine = ['Korean']\n",
        "spanish_cuisine = ['Spanish']\n",
        "thai_cuisine = ['Thai']\n",
        "american_cuisine = ['American']\n",
        "chinese_cuisine = ['Chinese']\n",
        "\n",
        "\n",
        "# 建立空的子recipe\n",
        "# Create empty list\n",
        "recipe_indian = []\n",
        "recipe_mexican = []\n",
        "recipe_french = []\n",
        "recipe_italian = []\n",
        "recipe_japanese = []\n",
        "recipe_korean = []\n",
        "recipe_spanish = []\n",
        "recipe_thai = []\n",
        "recipe_american = []\n",
        "recipe_chinese = []\n",
        "\n",
        "# classify cuisine\n",
        "for index,word_list in enumerate(recipe1):\n",
        "    # 轉小寫\n",
        "    # Transform the words to lowercase\n",
        "    lowercase_word_list = [word.lower() for word in word_list]\n",
        "\n",
        "    # 分類recipe\n",
        "    # Categorize\n",
        "    if any(keyword.lower() in lowercase_word_list for keyword in indian_cuisine):\n",
        "        recipe_indian.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in mexican_cuisine):\n",
        "        recipe_mexican.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in french_cuisine):\n",
        "        recipe_french.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in italian_cuisine):\n",
        "        recipe_italian.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in japanese_cuisine):\n",
        "        recipe_japanese.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in korean_cuisine):\n",
        "        recipe_korean.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in spanish_cuisine):\n",
        "        recipe_spanish.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in thai_cuisine):\n",
        "        recipe_thai.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in american_cuisine):\n",
        "        recipe_american.append(recipe[index])\n",
        "    elif any(keyword.lower() in lowercase_word_list for keyword in chinese_cuisine):\n",
        "        recipe_chinese.append(recipe[index])\n",
        "\n",
        "recipe_indian = pd.Series(recipe_indian)\n",
        "recipe_mexican = pd.Series(recipe_mexican)\n",
        "recipe_french = pd.Series(recipe_french)\n",
        "recipe_italian = pd.Series(recipe_italian)\n",
        "recipe_japanese = pd.Series(recipe_japanese)\n",
        "recipe_korean = pd.Series(recipe_korean)\n",
        "recipe_spanish = pd.Series(recipe_spanish)\n",
        "recipe_thai = pd.Series(recipe_thai)\n",
        "recipe_american = pd.Series(recipe_american)\n",
        "recipe_chinese = pd.Series(recipe_chinese)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrh3p9rlQiug",
        "outputId": "f574454c-ce9c-4a24-a330-0cc0038286e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Chinese Chicken Fried Rice II ['1 egg ', '1 ta...\n",
              "1      Mama's Asian Chicken and Rice ['1/3 cup warm w...\n",
              "2      Amber's Sesame Chicken ['1 cup all-purpose flo...\n",
              "3      Asian Chicken Salad ['2 tablespoons brown suga...\n",
              "4      Chinese Pepper Steak ['1 pound beef top sirloi...\n",
              "                             ...                        \n",
              "762    Seared Five-Spice Duck Breast with Snow Peas a...\n",
              "763    Sweet and Sour Curry Spring Rolls ['1 pound sh...\n",
              "764    Tea-Smoked Duck Legs with Mushroom and Orzo Ra...\n",
              "765    Beef in Oyster Sauce ['12 ounces beef fillet (...\n",
              "766    Coconut-Kaffir Leaf Poached Halibut with Saute...\n",
              "Length: 767, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "recipe_chinese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhcqRfcG9rp8"
      },
      "outputs": [],
      "source": [
        "# 保存到Google Drive以利後續使用\n",
        "# Stored the data in drive for further use\n",
        "recipe_indian.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_indian.csv', index=True)\n",
        "recipe_mexican.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_mexican.csv', index=True)\n",
        "recipe_french.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_french.csv', index=True)\n",
        "recipe_italian.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_italian.csv', index=True)\n",
        "recipe_japanese.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_japanese.csv', index=True)\n",
        "recipe_korean.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_korean.csv', index=True)\n",
        "recipe_spanish.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_spanish.csv', index=True)\n",
        "recipe_thai.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_thai.csv', index=True)\n",
        "recipe_american.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_american.csv', index=True)\n",
        "recipe_chinese.to_csv('/content/drive/My Drive/Recipe Recommendation/recipe_chinese.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# 下载停用词集合 \"english\"\n",
        "# download the stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# 获取英文停用词列表\n",
        "# get the stopwords\n",
        "english_stopwords = stopwords.words('english')\n",
        "\n",
        "# 添加额外的停用词\n",
        "# extend the stopwords (as our experiments show that the word \"make\" are frequent but not included in the stopwords)\n",
        "english_stopwords.append('make')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrqfIhtipK0_",
        "outputId": "13cc88e3-69af-4fbd-a41f-69d1c8e59853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw6RbmKTvGn4",
        "outputId": "0db075ae-54b8-45f9-f0cf-fd31a242fbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'make']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rzjs8aGdJSk",
        "outputId": "39217a75-99c4-40f9-c153-5d8c6de5a1c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Recipe Recommendation/recipe_ALL.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 事先對各子資料集進行tfidf轉換\n",
        "# Perform TF-IDF transformation on each sub dataset in advance.\n",
        "tfidf_ind = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_ind = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_ind.fit(recipe_indian)\n",
        "recipe_ind = tfidf_ind.fit_transform(recipe_indian)\n",
        "vectorizer_ind.fit(recipe_indian)\n",
        "recipe_IND = vectorizer_ind.fit_transform(recipe_indian)\n",
        "# 保存模型到文件\n",
        "# store the models in my drive\n",
        "joblib.dump(tfidf_ind, '/content/drive/My Drive/Recipe Recommendation/tfidf_ind.pkl')\n",
        "joblib.dump(vectorizer_ind, '/content/drive/My Drive/Recipe Recommendation/vectorizer_ind.pkl')\n",
        "joblib.dump(recipe_ind, '/content/drive/My Drive/Recipe Recommendation/recipe_ind.pkl')\n",
        "joblib.dump(recipe_IND, '/content/drive/My Drive/Recipe Recommendation/recipe_IND.pkl')\n",
        "\n",
        "\n",
        "# 2\n",
        "tfidf_mex = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_mex = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_mex.fit(recipe_mexican)\n",
        "vectorizer_mex.fit(recipe_mexican)\n",
        "recipe_mex = tfidf_mex.fit_transform(recipe_mexican)\n",
        "recipe_MEX = vectorizer_mex.fit_transform(recipe_mexican)\n",
        "joblib.dump(tfidf_mex, '/content/drive/My Drive/Recipe Recommendation/tfidf_mex.pkl')\n",
        "joblib.dump(vectorizer_mex, '/content/drive/My Drive/Recipe Recommendation/vectorizer_mex.pkl')\n",
        "joblib.dump(recipe_mex, '/content/drive/My Drive/Recipe Recommendation/recipe_mex.pkl')\n",
        "joblib.dump(recipe_MEX, '/content/drive/My Drive/Recipe Recommendation/recipe_MEX.pkl')\n",
        "\n",
        "\n",
        "# 3\n",
        "tfidf_fre = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_fre = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_fre.fit(recipe_french)\n",
        "vectorizer_fre.fit(recipe_french)\n",
        "recipe_fre = tfidf_fre.fit_transform(recipe_french)\n",
        "recipe_FRE = vectorizer_fre.fit_transform(recipe_french)\n",
        "joblib.dump(tfidf_fre, '/content/drive/My Drive/Recipe Recommendation/tfidf_fre.pkl')\n",
        "joblib.dump(vectorizer_fre, '/content/drive/My Drive/Recipe Recommendation/vectorizer_fre.pkl')\n",
        "joblib.dump(recipe_fre, '/content/drive/My Drive/Recipe Recommendation/recipe_fre.pkl')\n",
        "joblib.dump(recipe_FRE, '/content/drive/My Drive/Recipe Recommendation/recipe_FRE.pkl')\n",
        "\n",
        "# 4\n",
        "tfidf_ita = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_ita = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_ita.fit(recipe_italian)\n",
        "vectorizer_ita.fit(recipe_italian)\n",
        "recipe_ita = tfidf_ita.fit_transform(recipe_italian)\n",
        "recipe_ITA = vectorizer_ita.fit_transform(recipe_italian)\n",
        "joblib.dump(tfidf_ita, '/content/drive/My Drive/Recipe Recommendation/tfidf_ita.pkl')\n",
        "joblib.dump(vectorizer_ita, '/content/drive/My Drive/Recipe Recommendation/vectorizer_ita.pkl')\n",
        "joblib.dump(recipe_ita, '/content/drive/My Drive/Recipe Recommendation/recipe_ita.pkl')\n",
        "joblib.dump(recipe_ITA, '/content/drive/My Drive/Recipe Recommendation/recipe_ITA.pkl')\n",
        "\n",
        "\n",
        "# 5\n",
        "tfidf_jap = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_jap = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_jap.fit(recipe_japanese)\n",
        "vectorizer_jap.fit(recipe_japanese)\n",
        "recipe_jap = tfidf_jap.fit_transform(recipe_japanese)\n",
        "recipe_JAP = vectorizer_jap.fit_transform(recipe_japanese)\n",
        "joblib.dump(tfidf_jap, '/content/drive/My Drive/Recipe Recommendation/tfidf_jap.pkl')\n",
        "joblib.dump(vectorizer_jap, '/content/drive/My Drive/Recipe Recommendation/vectorizer_jap.pkl')\n",
        "joblib.dump(recipe_jap, '/content/drive/My Drive/Recipe Recommendation/recipe_jap.pkl')\n",
        "joblib.dump(recipe_JAP, '/content/drive/My Drive/Recipe Recommendation/recipe_JAP.pkl')\n",
        "\n",
        "\n",
        "# 6\n",
        "tfidf_kor = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_kor = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_kor.fit(recipe_korean)\n",
        "vectorizer_kor.fit(recipe_korean)\n",
        "recipe_kor = tfidf_kor.fit_transform(recipe_korean)\n",
        "recipe_KOR = vectorizer_kor.fit_transform(recipe_korean)\n",
        "joblib.dump(tfidf_kor, '/content/drive/My Drive/Recipe Recommendation/tfidf_kor.pkl')\n",
        "joblib.dump(vectorizer_kor, '/content/drive/My Drive/Recipe Recommendation/vectorizer_kor.pkl')\n",
        "joblib.dump(recipe_kor, '/content/drive/My Drive/Recipe Recommendation/recipe_kor.pkl')\n",
        "joblib.dump(recipe_KOR, '/content/drive/My Drive/Recipe Recommendation/recipe_KOR.pkl')\n",
        "\n",
        "\n",
        "# 7\n",
        "tfidf_spa = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_spa = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_spa.fit(recipe_spanish)\n",
        "vectorizer_spa.fit(recipe_spanish)\n",
        "recipe_spa = tfidf_spa.fit_transform(recipe_spanish)\n",
        "recipe_SPA = vectorizer_spa.fit_transform(recipe_spanish)\n",
        "joblib.dump(tfidf_spa, '/content/drive/My Drive/Recipe Recommendation/tfidf_spa.pkl')\n",
        "joblib.dump(vectorizer_spa, '/content/drive/My Drive/Recipe Recommendation/vectorizer_spa.pkl')\n",
        "joblib.dump(recipe_spa, '/content/drive/My Drive/Recipe Recommendation/recipe_spa.pkl')\n",
        "joblib.dump(recipe_SPA, '/content/drive/My Drive/Recipe Recommendation/recipe_SPA.pkl')\n",
        "\n",
        "\n",
        "# 8\n",
        "tfidf_tha = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_tha = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_tha.fit(recipe_thai)\n",
        "vectorizer_tha.fit(recipe_thai)\n",
        "recipe_tha = tfidf_tha.fit_transform(recipe_thai)\n",
        "recipe_THA = vectorizer_tha.fit_transform(recipe_thai)\n",
        "joblib.dump(tfidf_tha, '/content/drive/My Drive/Recipe Recommendation/tfidf_tha.pkl')\n",
        "joblib.dump(vectorizer_tha, '/content/drive/My Drive/Recipe Recommendation/vectorizer_tha.pkl')\n",
        "joblib.dump(recipe_tha, '/content/drive/My Drive/Recipe Recommendation/recipe_tha.pkl')\n",
        "joblib.dump(recipe_THA, '/content/drive/My Drive/Recipe Recommendation/recipe_THA.pkl')\n",
        "\n",
        "\n",
        "# 9\n",
        "tfidf_ame = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_ame = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_ame.fit(recipe_american)\n",
        "vectorizer_ame.fit(recipe_american)\n",
        "recipe_ame = tfidf_ame.fit_transform(recipe_american)\n",
        "recipe_AME = vectorizer_ame.fit_transform(recipe_american)\n",
        "joblib.dump(tfidf_ame, '/content/drive/My Drive/Recipe Recommendation/tfidf_ame.pkl')\n",
        "joblib.dump(vectorizer_ame, '/content/drive/My Drive/Recipe Recommendation/vectorizer_ame.pkl')\n",
        "joblib.dump(recipe_ame, '/content/drive/My Drive/Recipe Recommendation/recipe_ame.pkl')\n",
        "joblib.dump(recipe_AME, '/content/drive/My Drive/Recipe Recommendation/recipe_AME.pkl')\n",
        "\n",
        "\n",
        "# 10\n",
        "tfidf_chi = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_chi = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_chi.fit(recipe_chinese)\n",
        "vectorizer_chi.fit(recipe_chinese)\n",
        "recipe_chi = tfidf_chi.fit_transform(recipe_chinese)\n",
        "recipe_CHI = vectorizer_chi.fit_transform(recipe_chinese)\n",
        "joblib.dump(tfidf_chi, '/content/drive/My Drive/Recipe Recommendation/tfidf_chi.pkl')\n",
        "joblib.dump(vectorizer_chi, '/content/drive/My Drive/Recipe Recommendation/vectorizer_chi.pkl')\n",
        "joblib.dump(recipe_chi, '/content/drive/My Drive/Recipe Recommendation/recipe_chi.pkl')\n",
        "joblib.dump(recipe_CHI, '/content/drive/My Drive/Recipe Recommendation/recipe_CHI.pkl')\n",
        "\n",
        "# 11\n",
        "tfidf_all = TfidfVectorizer(lowercase=True, stop_words=english_stopwords, min_df=0.05, max_df=0.9, ngram_range = (1,3))\n",
        "vectorizer_all = CountVectorizer(lowercase=True, token_pattern=r'(?u)\\b\\w+\\b', stop_words=english_stopwords)\n",
        "tfidf_all.fit(recipe)\n",
        "vectorizer_all.fit(recipe)\n",
        "recipe_all = tfidf_all.fit_transform(recipe)\n",
        "recipe_ALL = vectorizer_all.fit_transform(recipe)\n",
        "joblib.dump(tfidf_all, '/content/drive/My Drive/Recipe Recommendation/tfidf_all.pkl')\n",
        "joblib.dump(vectorizer_all, '/content/drive/My Drive/Recipe Recommendation/vectorizer_all.pkl')\n",
        "joblib.dump(recipe_all, '/content/drive/My Drive/Recipe Recommendation/recipe_all.pkl')\n",
        "joblib.dump(recipe_ALL, '/content/drive/My Drive/Recipe Recommendation/recipe_ALL.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDwwgjviuGV_"
      },
      "outputs": [],
      "source": [
        "# load the models from my drive\n",
        "tfidf_indian = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_ind.pkl')\n",
        "vectorizer_indian = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_ind.pkl')\n",
        "recipe_ind = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_ind.pkl')\n",
        "recipe_IND = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_IND.pkl')\n",
        "\n",
        "\n",
        "tfidf_mexican = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_mex.pkl')\n",
        "vectorizer_mexican = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_mex.pkl')\n",
        "recipe_mex = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_mex.pkl')\n",
        "recipe_MEX = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_MEX.pkl')\n",
        "\n",
        "\n",
        "tfidf_french = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_fre.pkl')\n",
        "vectorizer_french = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_fre.pkl')\n",
        "recipe_fre = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_fre.pkl')\n",
        "recipe_FRE = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_FRE.pkl')\n",
        "\n",
        "\n",
        "tfidf_italian = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_ita.pkl')\n",
        "vectorizer_italian = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_ita.pkl')\n",
        "recipe_ita = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_ita.pkl')\n",
        "recipe_ITA = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_ITA.pkl')\n",
        "\n",
        "\n",
        "tfidf_japanese = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_jap.pkl')\n",
        "vectorizer_japanese = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_jap.pkl')\n",
        "recipe_jap = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_jap.pkl')\n",
        "recipe_JAP = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_JAP.pkl')\n",
        "\n",
        "\n",
        "tfidf_korean = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_kor.pkl')\n",
        "vectorizer_korean = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_kor.pkl')\n",
        "recipe_kor = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_kor.pkl')\n",
        "recipe_KOR = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_KOR.pkl')\n",
        "\n",
        "\n",
        "tfidf_spanish = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_spa.pkl')\n",
        "vectorizer_spanish = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_spa.pkl')\n",
        "recipe_spa = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_spa.pkl')\n",
        "recipe_SPA = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_SPA.pkl')\n",
        "\n",
        "\n",
        "tfidf_thai = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_tha.pkl')\n",
        "vectorizer_thai = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_tha.pkl')\n",
        "recipe_tha = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_tha.pkl')\n",
        "recipe_THA = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_THA.pkl')\n",
        "\n",
        "\n",
        "tfidf_american = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_ame.pkl')\n",
        "vectorizer_american = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_ame.pkl')\n",
        "recipe_ame = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_ame.pkl')\n",
        "recipe_AME = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_AME.pkl')\n",
        "\n",
        "\n",
        "tfidf_chinese = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_chi.pkl')\n",
        "vectorizer_chinese = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_chi.pkl')\n",
        "recipe_chi = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_chi.pkl')\n",
        "recipe_CHI = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_CHI.pkl')\n",
        "\n",
        "\n",
        "tfidf = joblib.load('/content/drive/My Drive/Recipe Recommendation/tfidf_all.pkl')\n",
        "vectorizer = joblib.load('/content/drive/My Drive/Recipe Recommendation/vectorizer_all.pkl')\n",
        "recipe_all = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_all.pkl')\n",
        "recipe_ALL = joblib.load('/content/drive/My Drive/Recipe Recommendation/recipe_ALL.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFZqXfswO6vh"
      },
      "outputs": [],
      "source": [
        "# 讀取之前存好的子recipe\n",
        "# load the recipes from my drive\n",
        "recipe_indian = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_indian.csv')\n",
        "recipe_mexican = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_mexican.csv')\n",
        "recipe_french = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_french.csv')\n",
        "recipe_italian = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_italian.csv')\n",
        "recipe_japanese = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_japanese.csv')\n",
        "recipe_korean = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_korean.csv')\n",
        "recipe_spanish = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_spanish.csv')\n",
        "recipe_thai = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_thai.csv')\n",
        "recipe_american = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_american.csv')\n",
        "recipe_chinese = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_chinese.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X25IqN2NQ79z",
        "outputId": "eabeca99-8b69-43a7-94b9-854d41c102b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Homemade Mac and Cheese Casserole ['8 ounces w...\n",
              "1        World's Best Lasagna ['1 pound sweet Italian s...\n",
              "2        Zesty Slow Cooker Chicken Barbecue ['6 frozen ...\n",
              "3        Boilermaker Tailgate Chili ['2 pounds ground b...\n",
              "4        Baked Ziti I ['1 pound dry ziti pasta ', '1 on...\n",
              "                               ...                        \n",
              "10527    Life Burger ['3 tablespoons honey or clear raw...\n",
              "10528    Lemon Asparagus Risotto ['1 pound/500 g aspara...\n",
              "10529    Fresh Mint Chip Gelato ['1 cup sugar', '2 tabl...\n",
              "10530    Tuscan Tomato and Bread Soup - Pappa al Pomodo...\n",
              "10531    Lamb and Eggplant Pastitsio ['1 large onion, c...\n",
              "Name: 0, Length: 10532, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "recipe_italian['0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x9Bbwp-d12C"
      },
      "outputs": [],
      "source": [
        "# 創建一個dictionary方便核對question\n",
        "# create a dictionary for comparison\n",
        "cuisines = {\n",
        "    \"indian_cuisine\": {\n",
        "        \"list\": indian_cuisine,\n",
        "        \"tfidf\": tfidf_indian,\n",
        "        \"vect\": vectorizer_indian,\n",
        "        \"transform\": recipe_ind,\n",
        "        \"transform1\": recipe_IND,\n",
        "        \"dataset\": recipe_indian\n",
        "    },\n",
        "    \"mexican_cuisine\": {\n",
        "        \"list\": mexican_cuisine,\n",
        "        \"tfidf\": tfidf_mexican,\n",
        "        \"vect\": vectorizer_mexican,\n",
        "        \"transform\": recipe_mex,\n",
        "        \"transform1\": recipe_MEX,\n",
        "        \"dataset\": recipe_mexican\n",
        "    },\n",
        "    \"french_cuisine\": {\n",
        "        \"list\": french_cuisine,\n",
        "        \"tfidf\": tfidf_french,\n",
        "        \"vect\": vectorizer_french,\n",
        "        \"transform\": recipe_fre,\n",
        "        \"transform1\": recipe_FRE,\n",
        "        \"dataset\": recipe_french\n",
        "    },\n",
        "    \"italian_cuisine\": {\n",
        "        \"list\": italian_cuisine,\n",
        "        \"tfidf\": tfidf_italian,\n",
        "        \"vect\": vectorizer_italian,\n",
        "        \"transform\": recipe_ita,\n",
        "        \"transform1\": recipe_ITA,\n",
        "        \"dataset\": recipe_italian\n",
        "    },\n",
        "    \"japanese_cuisine\": {\n",
        "        \"list\": japanese_cuisine,\n",
        "        \"tfidf\": tfidf_japanese,\n",
        "        \"vect\": vectorizer_japanese,\n",
        "        \"transform\": recipe_jap,\n",
        "        \"transform1\": recipe_JAP,\n",
        "        \"dataset\": recipe_japanese\n",
        "    },\n",
        "    \"korean_cuisine\": {\n",
        "        \"list\": korean_cuisine,\n",
        "        \"tfidf\": tfidf_korean,\n",
        "        \"vect\": vectorizer_korean,\n",
        "        \"transform\": recipe_kor,\n",
        "        \"transform1\": recipe_KOR,\n",
        "        \"dataset\": recipe_korean\n",
        "    },\n",
        "    \"spanish_cuisine\": {\n",
        "        \"list\": spanish_cuisine,\n",
        "        \"tfidf\": tfidf_spanish,\n",
        "        \"vect\": vectorizer_spanish,\n",
        "        \"transform\": recipe_spa,\n",
        "        \"transform1\": recipe_SPA,\n",
        "        \"dataset\": recipe_spanish\n",
        "    },\n",
        "    \"thai_cuisine\": {\n",
        "        \"list\": thai_cuisine,\n",
        "        \"tfidf\": tfidf_thai,\n",
        "        \"vect\": vectorizer_thai,\n",
        "        \"transform\": recipe_tha,\n",
        "        \"transform1\": recipe_THA,\n",
        "        \"dataset\": recipe_thai\n",
        "    },\n",
        "    \"american_cuisine\": {\n",
        "        \"list\": american_cuisine,\n",
        "        \"tfidf\": tfidf_american,\n",
        "        \"vect\": vectorizer_american,\n",
        "        \"transform\": recipe_ame,\n",
        "        \"transform1\": recipe_AME,\n",
        "        \"dataset\": recipe_american\n",
        "    },\n",
        "    \"chinese_cuisine\": {\n",
        "        \"list\": chinese_cuisine,\n",
        "        \"tfidf\": tfidf_chinese,\n",
        "        \"vect\": vectorizer_chinese,\n",
        "        \"transform\": recipe_chi,\n",
        "        \"transform1\": recipe_CHI,\n",
        "        \"dataset\": recipe_chinese\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EVs1TCwetrH",
        "outputId": "d1cdfb3d-9b55-4ca5-93d9-7118708cae24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is in your mind?\n",
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)? I want to make it chinese\n",
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)? I want to make it chinese\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is 0.4135151488163223:\n",
            "*Title:\n",
            "Chinese Style Steamed Fish   \n",
            "\n",
            "*Ingredients:\n",
            "'2 6-ounce red snapper fillets', '2 tablespoons dry white wine', '1 1/2 teaspoons minced peeled fresh ginger', '2 small garlic cloves, minced', '4 teaspoons soy sauce', '1 1/2 teaspoons oriental sesame oil', '2 tablespoons chopped fresh cilantro' \n",
            "\n",
            "*Instructions:\n",
            " Place small cake rack in large (12-inch-diameter) skillet; place 9-inch-diameter glass pie dish on rack. Put fish in dish; sprinkle lightly with salt and pepper. Sprinkle wine, ginger and garlic in dish around fish. Top fish with soy sauce, sesame oil and 1 tablespoon cilantro. Pour enough water into skillet to reach depth of 1 inch. Bring water to boil. Cover skillet; steam fish until just opaque in center, about 10 minutes. Transfer fish to plates; top with juices from dish and remaining 1 tablespoon cilantro.\n",
            "Place small cake rack in large (12-inch-diameter) skillet; place 9-inch-diameter glass pie dish on rack. Put fish in dish; sprinkle lightly with salt and pepper. Sprinkle wine, ginger and garlic in dish around fish. Top fish with soy sauce, sesame oil and 1 tablespoon cilantro. Pour enough water into skillet to reach depth of 1 inch. Bring water to boil. Cover skillet; steam fish until just opaque in center, about 10 minutes. Transfer fish to plates; top with juices from dish and remaining 1 tablespoon cilantro. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is 0.5002761655370566:\n",
            "*Title:\n",
            "Clams Steamed with Ginger and Scallions   \n",
            "\n",
            "*Ingredients:\n",
            "'2 teaspoons minced ginger', '3 tablespoons scallions, finely sliced', '1 tablespoon light soy sauce', '1 1/2 tablespoons Shao-Hsing wine, or sherry', '1 1/2 teaspoons sugar', '1 1/2 teaspoons Chinese white rice vinegar or distilled white vinegar', '1 tablespoon scallion oil (see Note, below)', '3 tablespoons vegetable stock', 'Pinch white pepper', '12 clams, medium, opened on the half-shell by a fishmonger', '8 cups boiling water', '6 sprigs coriander' \n",
            "\n",
            "*Instructions:\n",
            " Combine sauce ingredients in a bowl. Place clams in a steamproof dish. Stir sauce, pour over clams. Place dish on a rack in a wok over 6 cups boiling water, cover and steam, 1 1/2 to 2 minutes. Do not oversteam, or clams will become tough. Turn off heat and remove dish from steamer. Garnish with coriander and serve immediately.\n",
            "Combine sauce ingredients in a bowl. Place clams in a steamproof dish. Stir sauce, pour over clams. Place dish on a rack in a wok over 6 cups boiling water, cover and steam, 1 1/2 to 2 minutes. Do not oversteam, or clams will become tough. Turn off heat and remove dish from steamer. Garnish with coriander and serve immediately. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is 0.5069165928966654:\n",
            "*Title:\n",
            "Grilled Tuna Teriyaki  \n",
            "\n",
            "*Ingredients:\n",
            "'2 tablespoons light soy sauce ', '1 tablespoon Chinese rice wine ', '1 tablespoon minced fresh ginger root ', '1 large clove garlic, minced ', '4 (6 ounce) tuna steaks (about 3/4 inch thick) ', '1 tablespoon vegetable oil ', '' \n",
            "\n",
            "*Instructions:\n",
            " Stir soy sauce, rice wine, ginger, and garlic together in a shallow dish. Place tuna in the marinade, and turn to coat. Cover dish and refrigerate for at least 30 minutes.\n",
            "Preheat grill for medium-high heat.\n",
            "Remove tuna from marinade and discard remaining liquid. Brush both sides of steaks with oil.\n",
            "Cook tuna on the preheated grill until cooked through, 3 to 6 minutes per side.\n",
            " \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question = input(\"What is in your mind?\\n\")\n",
        "question_lower = question.lower()\n",
        "\n",
        "# Iterate through cuisines and their corresponding datasets\n",
        "for typ, cuisine in cuisines.items():\n",
        "    for key_word in cuisine[\"list\"]:\n",
        "        if key_word.lower() in question_lower:\n",
        "            X = cuisine[\"tfidf\"].transform([question])\n",
        "            Y = cuisine[\"vect\"].transform([question])\n",
        "            cosine_sim = np.ravel(cosine_similarity(X, cuisine[\"transform\"]))\n",
        "            recipe_intersections = cuisine[\"transform1\"].multiply(Y).sum(axis=1)\n",
        "            recipe_unions = cuisine[\"transform1\"].sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "            jaccard_similarity = recipe_intersections / recipe_unions\n",
        "            jaccard_sim = np.ravel(jaccard_similarity)\n",
        "            sim = cosine_sim + jaccard_sim\n",
        "            top_indices = np.argsort(sim)[-3:]\n",
        "            print(question)\n",
        "            print('---------------------------------------------------------------------------')\n",
        "            for i, index in enumerate(top_indices, 1):\n",
        "                recipe_info = re.split('\\[|\\]', cuisine[\"dataset\"][index])\n",
        "                print(f\"Recommendation {i} , The similarity is {sim[index]}:\")\n",
        "                print('*Title:')\n",
        "                print(recipe_info[0],'\\n')\n",
        "                print('*Ingredients:')\n",
        "                print(recipe_info[1],'\\n')\n",
        "                print('*Instructions:')\n",
        "                print(recipe_info[2],'\\n')\n",
        "                print('\\n')\n",
        "            break  # 一旦配到，立即跳出cusine 的 for loop\n",
        "    else:  # 如果未配到，執行下面的code\n",
        "        continue  # 往下一個cuisine測試匹配\n",
        "    break  # 一旦配到，立即跳出整個for loop\n",
        "else:  # 如果所有的子recipe都没有匹配到，從主recipe找全部\n",
        "    X = tfidf.transform([question])\n",
        "    Y = vectorizer.transform([question])\n",
        "    cosine_sim = np.ravel(cosine_similarity(X, recipe_all))\n",
        "    recipe_intersections = recipe_ALL.multiply(Y).sum(axis=1)\n",
        "    recipe_unions = recipe_ALL.sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "    jaccard_similarity = recipe_intersections / recipe_unions\n",
        "    jaccard_sim = np.ravel(jaccard_similarity)\n",
        "    sim = cosine_sim + jaccard_sim\n",
        "    top_indices = np.argsort(sim)[-3:]\n",
        "    print(question)\n",
        "    print('---------------------------------------------------------------------------')\n",
        "    for i, index in enumerate(top_indices, 1):\n",
        "        recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "        print(f\"Recommendation {i} , The similarity is {sim[index]}:\")\n",
        "        print('*Title:')\n",
        "        print(recipe_info[0],'\\n')\n",
        "        print('*Ingredients:')\n",
        "        print(recipe_info[1],'\\n')\n",
        "        print('*Instructions:')\n",
        "        print(recipe_info[2],'\\n')\n",
        "        print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu3TJrpm8LVf"
      },
      "source": [
        "# 統整所需的程式碼 / Summarize the codes needed for building my model into an user innterface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LetnZ8TU8RZj",
        "outputId": "fb24535a-ec02-4bd9-b5bb-7e3b35dc62ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "What is in your mind?\n",
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)? I want to make it chinese\n",
            "I have tofu and soy sauce and ginger. Can you recommend a savory dish that can be cooked in medium (30-60 minutes)? I want to make it chinese\n",
            "---------------------------------------------------------------------------\n",
            "Recommendation 1 , The similarity is 0.4135151488163223:\n",
            "*Title:\n",
            "Chinese Style Steamed Fish   \n",
            "\n",
            "*Ingredients:\n",
            "'2 6-ounce red snapper fillets', '2 tablespoons dry white wine', '1 1/2 teaspoons minced peeled fresh ginger', '2 small garlic cloves, minced', '4 teaspoons soy sauce', '1 1/2 teaspoons oriental sesame oil', '2 tablespoons chopped fresh cilantro' \n",
            "\n",
            "*Instructions:\n",
            " Place small cake rack in large (12-inch-diameter) skillet; place 9-inch-diameter glass pie dish on rack. Put fish in dish; sprinkle lightly with salt and pepper. Sprinkle wine, ginger and garlic in dish around fish. Top fish with soy sauce, sesame oil and 1 tablespoon cilantro. Pour enough water into skillet to reach depth of 1 inch. Bring water to boil. Cover skillet; steam fish until just opaque in center, about 10 minutes. Transfer fish to plates; top with juices from dish and remaining 1 tablespoon cilantro.\n",
            "Place small cake rack in large (12-inch-diameter) skillet; place 9-inch-diameter glass pie dish on rack. Put fish in dish; sprinkle lightly with salt and pepper. Sprinkle wine, ginger and garlic in dish around fish. Top fish with soy sauce, sesame oil and 1 tablespoon cilantro. Pour enough water into skillet to reach depth of 1 inch. Bring water to boil. Cover skillet; steam fish until just opaque in center, about 10 minutes. Transfer fish to plates; top with juices from dish and remaining 1 tablespoon cilantro. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 2 , The similarity is 0.5002761655370566:\n",
            "*Title:\n",
            "Clams Steamed with Ginger and Scallions   \n",
            "\n",
            "*Ingredients:\n",
            "'2 teaspoons minced ginger', '3 tablespoons scallions, finely sliced', '1 tablespoon light soy sauce', '1 1/2 tablespoons Shao-Hsing wine, or sherry', '1 1/2 teaspoons sugar', '1 1/2 teaspoons Chinese white rice vinegar or distilled white vinegar', '1 tablespoon scallion oil (see Note, below)', '3 tablespoons vegetable stock', 'Pinch white pepper', '12 clams, medium, opened on the half-shell by a fishmonger', '8 cups boiling water', '6 sprigs coriander' \n",
            "\n",
            "*Instructions:\n",
            " Combine sauce ingredients in a bowl. Place clams in a steamproof dish. Stir sauce, pour over clams. Place dish on a rack in a wok over 6 cups boiling water, cover and steam, 1 1/2 to 2 minutes. Do not oversteam, or clams will become tough. Turn off heat and remove dish from steamer. Garnish with coriander and serve immediately.\n",
            "Combine sauce ingredients in a bowl. Place clams in a steamproof dish. Stir sauce, pour over clams. Place dish on a rack in a wok over 6 cups boiling water, cover and steam, 1 1/2 to 2 minutes. Do not oversteam, or clams will become tough. Turn off heat and remove dish from steamer. Garnish with coriander and serve immediately. \n",
            "\n",
            "\n",
            "\n",
            "Recommendation 3 , The similarity is 0.5069165928966654:\n",
            "*Title:\n",
            "Grilled Tuna Teriyaki  \n",
            "\n",
            "*Ingredients:\n",
            "'2 tablespoons light soy sauce ', '1 tablespoon Chinese rice wine ', '1 tablespoon minced fresh ginger root ', '1 large clove garlic, minced ', '4 (6 ounce) tuna steaks (about 3/4 inch thick) ', '1 tablespoon vegetable oil ', '' \n",
            "\n",
            "*Instructions:\n",
            " Stir soy sauce, rice wine, ginger, and garlic together in a shallow dish. Place tuna in the marinade, and turn to coat. Cover dish and refrigerate for at least 30 minutes.\n",
            "Preheat grill for medium-high heat.\n",
            "Remove tuna from marinade and discard remaining liquid. Brush both sides of steaks with oil.\n",
            "Cook tuna on the preheated grill until cooked through, 3 to 6 minutes per side.\n",
            " \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 讀主recipe & 資料前處理\n",
        "# read the main recipe and preprocess data\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv(r'/content/drive/MyDrive/all_recipe.csv')\n",
        "recipe = data['title'].astype(str) + ' ' + data['ingredients'].astype(str) + ' ' + data['instructions'].astype(str)\n",
        "recipe = [re.sub(r'\\b\\w*ADVERTISEMENT\\w*\\b', '', sentence) for sentence in recipe]\n",
        "recipe = [''.join(words) for words in recipe]\n",
        "recipe = pd.Series(recipe)\n",
        "# 讀取之前存好的子recipe\n",
        "# read the stored recipes\n",
        "recipe_indian = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_indian.csv')\n",
        "recipe_mexican = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_mexican.csv')\n",
        "recipe_french = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_french.csv')\n",
        "recipe_italian = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_italian.csv')\n",
        "recipe_japanese = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_japanese.csv')\n",
        "recipe_korean = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_korean.csv')\n",
        "recipe_spanish = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_spanish.csv')\n",
        "recipe_thai = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_thai.csv')\n",
        "recipe_american = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_american.csv')\n",
        "recipe_chinese = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_chinese.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 讀取事先訓練好的model\n",
        "# load the stored models\n",
        "tfidf_indian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_ind.pkl')\n",
        "vectorizer_indian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_ind.pkl')\n",
        "recipe_ind = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ind.pkl')\n",
        "recipe_IND = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_IND.pkl')\n",
        "\n",
        "tfidf_mexican = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_mex.pkl')\n",
        "vectorizer_mexican = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_mex.pkl')\n",
        "recipe_mex = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_mex.pkl')\n",
        "recipe_MEX = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_MEX.pkl')\n",
        "\n",
        "tfidf_french = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_fre.pkl')\n",
        "vectorizer_french = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_fre.pkl')\n",
        "recipe_fre = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_fre.pkl')\n",
        "recipe_FRE = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_FRE.pkl')\n",
        "\n",
        "tfidf_italian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_ita.pkl')\n",
        "vectorizer_italian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_ita.pkl')\n",
        "recipe_ita = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ita.pkl')\n",
        "recipe_ITA = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ITA.pkl')\n",
        "\n",
        "tfidf_japanese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_jap.pkl')\n",
        "vectorizer_japanese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_jap.pkl')\n",
        "recipe_jap = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_jap.pkl')\n",
        "recipe_JAP = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_JAP.pkl')\n",
        "\n",
        "tfidf_korean = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_kor.pkl')\n",
        "vectorizer_korean = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_kor.pkl')\n",
        "recipe_kor = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_kor.pkl')\n",
        "recipe_KOR = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_KOR.pkl')\n",
        "\n",
        "tfidf_spanish = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_spa.pkl')\n",
        "vectorizer_spanish = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_spa.pkl')\n",
        "recipe_spa = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_spa.pkl')\n",
        "recipe_SPA = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_SPA.pkl')\n",
        "\n",
        "tfidf_thai = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_tha.pkl')\n",
        "vectorizer_thai = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_tha.pkl')\n",
        "recipe_tha = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_tha.pkl')\n",
        "recipe_THA = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_THA.pkl')\n",
        "\n",
        "tfidf_american = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_ame.pkl')\n",
        "vectorizer_american = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_ame.pkl')\n",
        "recipe_ame = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ame.pkl')\n",
        "recipe_AME = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_AME.pkl')\n",
        "\n",
        "tfidf_chinese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_chi.pkl')\n",
        "vectorizer_chinese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_chi.pkl')\n",
        "recipe_chi = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_chi.pkl')\n",
        "recipe_CHI = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_CHI.pkl')\n",
        "\n",
        "tfidf = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_all.pkl')\n",
        "vectorizer = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_all.pkl')\n",
        "recipe_all = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_all.pkl')\n",
        "recipe_ALL = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ALL.pkl')\n",
        "\n",
        "indian_cuisine = ['Indian'] #'Curry', 'Tandoori Chicken', 'Biryani', 'Naan', 'Samosa', 'Masala Dosa', 'Chole Bhature', 'Rogan Josh',\n",
        "mexican_cuisine = ['Mexican'] #'Tacos', 'Burritos', 'Enchiladas', 'Guacamole', 'Quesadillas', 'Fajitas', 'Salsa', 'Mole',\n",
        "french_cuisine = ['French'] #'Croissant', 'Baguette', 'Coq au Vin', 'Beef Bourguignon', 'Ratatouille', 'Escargot', 'Bouillabaisse', 'Quiche Lorraine',\n",
        "italian_cuisine = ['Italian'] #'Pizza', 'Pasta', 'Risotto', 'Lasagna', 'Tiramisu', 'Gelato', 'Bruschetta', 'Caprese Salad',\n",
        "japanese_cuisine = ['Japanese'] #'Sushi', 'Sashimi', 'Ramen', 'Tempura', 'Yakitori', 'Miso Soup', 'Tonkatsu', 'Matcha',\n",
        "korean_cuisine = ['Korean'] #'Kimchi', 'Bibimbap', 'Bulgogi', 'Kimbap', 'Tteokbokki', 'Japchae', 'Samgyeopsal', 'Galbi',\n",
        "spanish_cuisine = ['Spanish'] #'Paella', 'Tapas', 'Gazpacho', 'Tortilla Española', 'Churros', 'Jamón Ibérico', 'Sangria', 'Patatas Bravas',\n",
        "thai_cuisine = ['Thai'] #'Pad Thai', 'Tom Yum Goong', 'Green Curry', 'Som Tum (Papaya Salad)', 'Massaman Curry', 'Khao Pad (Fried Rice)', 'Pad See Ew', 'Mango Sticky Rice',\n",
        "american_cuisine = ['American'] #'Hamburger', 'Hotdog', 'BBQ Ribs', 'Fried Chicken', 'Apple Pie', 'Macaroni and Cheese', 'Clam Chowder', 'Pancakes',\n",
        "chinese_cuisine = ['Chinese'] #'Kung Pao Chicken', 'Peking Duck', 'Dim Sum', 'Mapo Tofu', 'Spring Rolls', 'Fried Rice', 'Chow Mein', 'Hot Pot', 'Dumplings',\n",
        "\n",
        "\n",
        "# 創建一個dictionary方便核對question\n",
        "# create a dictionary for comparison\n",
        "cuisines = {\n",
        "    \"indian_cuisine\": {\n",
        "        \"list\": indian_cuisine,\n",
        "        \"tfidf\": tfidf_indian,\n",
        "        \"vect\": vectorizer_indian,\n",
        "        \"transform\": recipe_ind,\n",
        "        \"transform1\": recipe_IND,\n",
        "        \"dataset\": recipe_indian\n",
        "    },\n",
        "    \"mexican_cuisine\": {\n",
        "        \"list\": mexican_cuisine,\n",
        "        \"tfidf\": tfidf_mexican,\n",
        "        \"vect\": vectorizer_mexican,\n",
        "        \"transform\": recipe_mex,\n",
        "        \"transform1\": recipe_MEX,\n",
        "        \"dataset\": recipe_mexican\n",
        "    },\n",
        "    \"french_cuisine\": {\n",
        "        \"list\": french_cuisine,\n",
        "        \"tfidf\": tfidf_french,\n",
        "        \"vect\": vectorizer_french,\n",
        "        \"transform\": recipe_fre,\n",
        "        \"transform1\": recipe_FRE,\n",
        "        \"dataset\": recipe_french\n",
        "    },\n",
        "    \"italian_cuisine\": {\n",
        "        \"list\": italian_cuisine,\n",
        "        \"tfidf\": tfidf_italian,\n",
        "        \"vect\": vectorizer_italian,\n",
        "        \"transform\": recipe_ita,\n",
        "        \"transform1\": recipe_ITA,\n",
        "        \"dataset\": recipe_italian\n",
        "    },\n",
        "    \"japanese_cuisine\": {\n",
        "        \"list\": japanese_cuisine,\n",
        "        \"tfidf\": tfidf_japanese,\n",
        "        \"vect\": vectorizer_japanese,\n",
        "        \"transform\": recipe_jap,\n",
        "        \"transform1\": recipe_JAP,\n",
        "        \"dataset\": recipe_japanese\n",
        "    },\n",
        "    \"korean_cuisine\": {\n",
        "        \"list\": korean_cuisine,\n",
        "        \"tfidf\": tfidf_korean,\n",
        "        \"vect\": vectorizer_korean,\n",
        "        \"transform\": recipe_kor,\n",
        "        \"transform1\": recipe_KOR,\n",
        "        \"dataset\": recipe_korean\n",
        "    },\n",
        "    \"spanish_cuisine\": {\n",
        "        \"list\": spanish_cuisine,\n",
        "        \"tfidf\": tfidf_spanish,\n",
        "        \"vect\": vectorizer_spanish,\n",
        "        \"transform\": recipe_spa,\n",
        "        \"transform1\": recipe_SPA,\n",
        "        \"dataset\": recipe_spanish\n",
        "    },\n",
        "    \"thai_cuisine\": {\n",
        "        \"list\": thai_cuisine,\n",
        "        \"tfidf\": tfidf_thai,\n",
        "        \"vect\": vectorizer_thai,\n",
        "        \"transform\": recipe_tha,\n",
        "        \"transform1\": recipe_THA,\n",
        "        \"dataset\": recipe_thai\n",
        "    },\n",
        "    \"american_cuisine\": {\n",
        "        \"list\": american_cuisine,\n",
        "        \"tfidf\": tfidf_american,\n",
        "        \"vect\": vectorizer_american,\n",
        "        \"transform\": recipe_ame,\n",
        "        \"transform1\": recipe_AME,\n",
        "        \"dataset\": recipe_american\n",
        "    },\n",
        "    \"chinese_cuisine\": {\n",
        "        \"list\": chinese_cuisine,\n",
        "        \"tfidf\": tfidf_chinese,\n",
        "        \"vect\": vectorizer_chinese,\n",
        "        \"transform\": recipe_chi,\n",
        "        \"transform1\": recipe_CHI,\n",
        "        \"dataset\": recipe_chinese\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 分析使用者的輸入並比對 (主要的模型輸出code)\n",
        "# make comparison and print the results\n",
        "question = input(\"What is in your mind?\\n\")\n",
        "question_lower = question.lower()\n",
        "\n",
        "for typ, cuisine in cuisines.items():\n",
        "    for key_word in cuisine[\"list\"]:\n",
        "        if key_word.lower() in question_lower:\n",
        "            X = cuisine[\"tfidf\"].transform([question])\n",
        "            Y = cuisine[\"vect\"].transform([question]).reshape(1, -1)\n",
        "            cosine_sim = np.ravel(cosine_similarity(X, cuisine[\"transform\"]))\n",
        "            recipe_intersections = cuisine[\"transform1\"].multiply(Y).sum(axis=1)\n",
        "            recipe_unions = cuisine[\"transform1\"].sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "            jaccard_similarity = recipe_intersections / recipe_unions\n",
        "            jaccard_sim = np.ravel(jaccard_similarity)\n",
        "            sim = cosine_sim + jaccard_sim\n",
        "            top_indices = np.argsort(sim)[-3:]\n",
        "            print(question)\n",
        "            print('---------------------------------------------------------------------------')\n",
        "            for i, index in enumerate(top_indices, 1):\n",
        "                recipe_info = re.split('\\[|\\]', cuisine[\"dataset\"]['0'][index])\n",
        "                print(f\"Recommendation {i} , The similarity is {sim[index]}:\")\n",
        "                print('*Title:')\n",
        "                print(recipe_info[0],'\\n')\n",
        "                print('*Ingredients:')\n",
        "                print(recipe_info[1],'\\n')\n",
        "                print('*Instructions:')\n",
        "                print(recipe_info[2],'\\n')\n",
        "                print('\\n')\n",
        "            break\n",
        "    else:\n",
        "        continue\n",
        "    break\n",
        "else:\n",
        "    X = tfidf.transform([question])\n",
        "    Y = vectorizer.transform([question])\n",
        "    cosine_sim = np.ravel(cosine_similarity(X, recipe_all))\n",
        "    recipe_intersections = recipe_ALL.multiply(Y).sum(axis=1)\n",
        "    recipe_unions = recipe_ALL.sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "    jaccard_similarity = recipe_intersections / recipe_unions\n",
        "    jaccard_sim = np.ravel(jaccard_similarity)\n",
        "    sim = cosine_sim + jaccard_sim\n",
        "    top_indices = np.argsort(sim)[-3:]\n",
        "    print(question)\n",
        "    print('---------------------------------------------------------------------------')\n",
        "    for i, index in enumerate(top_indices, 1):\n",
        "        recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "        print(f\"Recommendation {i} , The similarity is {sim[index]}:\")\n",
        "        print('*Title:')\n",
        "        print(recipe_info[0],'\\n')\n",
        "        print('*Ingredients:')\n",
        "        print(recipe_info[1],'\\n')\n",
        "        print('*Instructions:')\n",
        "        print(recipe_info[2],'\\n')\n",
        "        print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_italian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPWwfRoF9_W4",
        "outputId": "209835b7-0f15-4a9d-e653-7fdc6e49b2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Unnamed: 0                                                    0\n",
              "       0             Homemade Mac and Cheese Casserole ['8 ounces w...\n",
              "1      Unnamed: 0                                                    1\n",
              "       0             World's Best Lasagna ['1 pound sweet Italian s...\n",
              "2      Unnamed: 0                                                    2\n",
              "                                           ...                        \n",
              "10529  0             Fresh Mint Chip Gelato ['1 cup sugar', '2 tabl...\n",
              "10530  Unnamed: 0                                                10530\n",
              "       0             Tuscan Tomato and Bread Soup - Pappa al Pomodo...\n",
              "10531  Unnamed: 0                                                10531\n",
              "       0             Lamb and Eggplant Pastitsio ['1 large onion, c...\n",
              "Length: 21064, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Transform1 shape:\", cuisine[\"transform1\"].shape)\n",
        "print(\"Y shape:\", Y.transpose().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MGj38ZssRRk",
        "outputId": "4bc458fe-782c-4139-d13f-aa745dc68476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transform1 shape: (10532, 12366)\n",
            "Y shape: (12229, 1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}